{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ae23b4-73ff-42fa-b9c7-0ac69b71e02d",
   "metadata": {},
   "source": [
    "# Homework 3 - CNN on Multilabel remote sensing images\n",
    "## By: Syed Ali Murad Tahir\n",
    "\n",
    "In this homework we will be performing CNN on UCMerced dataset. This dataset contains Multispectral images. \n",
    "\n",
    "\n",
    "The task is divided into following step\n",
    "\n",
    "1)  Prepairing data\n",
    "2) The data we get, we divide that data, into training, test and validation. We divide training data into training and test\n",
    "3) To pretrain the model in order to avoid overfitting, we can use pretrained data already provided to us. Or, we can perform data augmentation\n",
    "to pre train the data so we have more samples of data\n",
    "4) Now we perform Convolution. So we choose the number of layers, neuron in that layer and the activation function of that layer (Check if need to perform padding before,). For padding check the following link: https://www.youtube.com/watch?v=mTVf7BN7S8w&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=27\n",
    "5) Then we add Max pooling to take out dominant features\n",
    "6) We can add dropout\n",
    "7) Then we have to perform flatten the data\n",
    "8) We can add a desne layer (Check if we need it or not) -> These are actually the hidden layers we specify when performing forward propgation\n",
    "9) Then we train or data\n",
    "10) After that we check our results on test data to check for overfitting\n",
    "11) At the end we check validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849277b8-81c2-4a68-8b4d-f8be2b5b5e12",
   "metadata": {},
   "source": [
    "## Understanding the dataset\n",
    "\n",
    "This is a 21 class land use image dataset meant for research purposes. However, for multilabel, we only have 17 labels\n",
    "\n",
    "There are 100 images for each of the following classes:\n",
    "    \n",
    "    \n",
    " 1) airplane\t\n",
    " 2) bare-soil\t\n",
    " 3) buildings\t\n",
    " 4) cars\t\n",
    " 5) chaparral\t\n",
    " 6) court\t\n",
    " 7) dock\t\n",
    " 8) field\t\n",
    " 9) grass\t\n",
    " 10) mobile-home\t\n",
    " 11) pavement\t\n",
    " 12) sand\t\n",
    " 13) sea\t\n",
    " 14) ship\t\n",
    " 15) tanks\t\n",
    " 16) trees\t\n",
    " 17) water\n",
    "\n",
    "Each image measures 256x256 pixels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc67344-a238-412f-8080-3c4d35354b82",
   "metadata": {},
   "source": [
    "## Imporint Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4e94269a-5bca-4a57-8c42-5f7439f4773a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T19:06:43.295767Z",
     "iopub.status.busy": "2022-07-15T19:06:43.295407Z",
     "iopub.status.idle": "2022-07-15T19:06:43.302473Z",
     "shell.execute_reply": "2022-07-15T19:06:43.301369Z",
     "shell.execute_reply.started": "2022-07-15T19:06:43.295741Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from simple_downloader import download\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, f1_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d177c7b-b47a-40b1-9be2-4ba6c56240fe",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8c1fb-493d-4f50-982e-7fa7bcdf621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = Path(\"./Hw3_data\")\n",
    "download_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44799501-6f9f-48f3-972f-e06da44261b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUB_URL = \"https://tubcloud.tu-berlin.de/s/H4QHX5GPDY6wDog/download/UCMerced_LandUse.zip\"\n",
    "output_file = download(TUB_URL, \"./Hw3_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae871bb-0c4f-4ccb-9e22-7081116dd301",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipf = zipfile.ZipFile(output_file)\n",
    "zipf.extractall(path=\"Hw3_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bc050-301b-4730-9dff-b0a59de81aa9",
   "metadata": {},
   "source": [
    "## Visualizing our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93d92a8-6d59-46b2-b706-c12aa21c341d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T16:46:27.074950Z",
     "iopub.status.busy": "2022-07-15T16:46:27.074389Z",
     "iopub.status.idle": "2022-07-15T16:46:27.843944Z",
     "shell.execute_reply": "2022-07-15T16:46:27.843065Z",
     "shell.execute_reply.started": "2022-07-15T16:46:27.074947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /notebooks/Hw3_data/UCMerced_LandUse/multilabels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGE\\LABEL</th>\n",
       "      <th>airplane</th>\n",
       "      <th>bare-soil</th>\n",
       "      <th>buildings</th>\n",
       "      <th>cars</th>\n",
       "      <th>chaparral</th>\n",
       "      <th>court</th>\n",
       "      <th>dock</th>\n",
       "      <th>field</th>\n",
       "      <th>grass</th>\n",
       "      <th>mobile-home</th>\n",
       "      <th>pavement</th>\n",
       "      <th>sand</th>\n",
       "      <th>sea</th>\n",
       "      <th>ship</th>\n",
       "      <th>tanks</th>\n",
       "      <th>trees</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agricultural00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agricultural01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agricultural02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agricultural03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agricultural04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>tenniscourt95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>tenniscourt96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>tenniscourt97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>tenniscourt98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>tenniscourt99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IMAGE\\LABEL  airplane  bare-soil  buildings  cars  chaparral  court  \\\n",
       "0     agricultural00         0          0          0     0          0      0   \n",
       "1     agricultural01         0          0          0     0          0      0   \n",
       "2     agricultural02         0          0          0     0          0      0   \n",
       "3     agricultural03         0          0          0     0          0      0   \n",
       "4     agricultural04         0          0          0     0          0      0   \n",
       "...              ...       ...        ...        ...   ...        ...    ...   \n",
       "2095   tenniscourt95         0          1          0     0          0      1   \n",
       "2096   tenniscourt96         0          1          1     1          0      1   \n",
       "2097   tenniscourt97         0          1          1     1          0      1   \n",
       "2098   tenniscourt98         0          1          1     1          0      1   \n",
       "2099   tenniscourt99         0          1          0     1          0      1   \n",
       "\n",
       "      dock  field  grass  mobile-home  pavement  sand  sea  ship  tanks  \\\n",
       "0        0      1      0            0         0     0    0     0      0   \n",
       "1        0      1      0            0         0     0    0     0      0   \n",
       "2        0      1      0            0         0     0    0     0      0   \n",
       "3        0      1      0            0         0     0    0     0      0   \n",
       "4        0      0      0            0         0     0    0     0      0   \n",
       "...    ...    ...    ...          ...       ...   ...  ...   ...    ...   \n",
       "2095     0      0      1            0         1     0    0     0      0   \n",
       "2096     0      0      1            0         1     0    0     0      0   \n",
       "2097     0      0      1            0         1     0    0     0      0   \n",
       "2098     0      0      1            0         1     0    0     0      0   \n",
       "2099     0      0      1            0         1     0    0     0      0   \n",
       "\n",
       "      trees  water  \n",
       "0         1      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         1      0  \n",
       "...     ...    ...  \n",
       "2095      0      0  \n",
       "2096      1      0  \n",
       "2097      1      0  \n",
       "2098      1      0  \n",
       "2099      1      0  \n",
       "\n",
       "[2100 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Go to different file directory\n",
    "path = os.path.join(\"/notebooks\", \"Hw3_data\", \"UCMerced_LandUse\", \"multilabels\", \"\")\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "\n",
    "data = pd.DataFrame(pd.read_excel(\"LandUse_Multilabeled.xlsx\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7b62f0-ffc1-49e6-a73c-2f9d269bd06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T16:47:09.574126Z",
     "iopub.status.busy": "2022-07-15T16:47:09.573735Z",
     "iopub.status.idle": "2022-07-15T16:47:09.825056Z",
     "shell.execute_reply": "2022-07-15T16:47:09.824109Z",
     "shell.execute_reply.started": "2022-07-15T16:47:09.574099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Number of labels\n",
      "airplane                 100\n",
      "bare-soil                718\n",
      "buildings                691\n",
      "cars                     886\n",
      "chaparral                115\n",
      "court                    105\n",
      "dock                     100\n",
      "field                    103\n",
      "grass                    975\n",
      "mobile-home              102\n",
      "pavement                1300\n",
      "sand                     294\n",
      "sea                      100\n",
      "ship                     102\n",
      "tanks                    100\n",
      "trees                   1009\n",
      "water                    203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Total no. of labels that belong to each class')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAKUCAYAAAC0ShQWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABH40lEQVR4nO3deZhcVZ3/8fc3CRD2NfADAgSQRXZj2EQERAEFBRUZGBgRQQZFhZFRggugwIAOLoACMqKACxoUBXVUFlkGFEMiO2EJECWsAdkE2cL398e9nVR3ujsd0nXrJP1+PU8/XXVrOd+qrq761LnnnBuZiSRJksozrNMFSJIkqXcGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdSkgkRERsQbOl1Hq4j4WEQ8FhH/iIgVe1w2pq55xADuZ8eImP46a3jdt+3lvqZFxDsG4756ue8BPx+DeduFzWA9Fz6nWhgY1KQBqENK189rEfHPlvP793GbQQsXnRIRiwBfB3bJzKUy88lO1zQvIuK8iDhxEO/v6og4ZLDurwQR8eGIuK7TdUjqnd8ypAHIzKW6TkfENOCQzLyicxU1ZhVgJHBHpwuRpKHIHjVpPkTEYhHxzYh4uP75Zr1tSeC3wGotPW+rRcRWEfGniHg6Ih6JiG9FxKIDbOvqiDghIq6PiOci4rKIWKnl8vdGxB31fV8dEW+cz8ewPnB3fbWnI+IPA7ivgyJiSl3f/RHx771c53MR8US9C3L/lu2LRcSpEfG3elfr2RGxeB/tHB0RD9Xt3B0RO/dynUOB/YHP1s//r1ou3iIibo2IZyLipxExsr7N8hHx64iYERFP1adH15edBGwPfKu+v2/181R8pH4uH4mIo1pqGhYR4yPivoh4MiImRMQKfTzG1SLi0oj4e0RMjYiPtlx2fH3bC+rn4I6IGNdy+diIuKm+7KL6Mc7Rs1i/Rs4Gtq0f09P19mXr+54REX+NiC9ERK+fF3N7THX7j9bP9bURsXHLZYtHxNfqNp6JiOt6/M33r18PT0TE5/t6sgdwP13X6/P1GREr1X/vp+vn/P+6HvNAXm9S22SmP/74Mw8/wDTgHfXpLwM3ACsDo4A/AifUl+0ITO9x2zcD21D1Zo8BpgBHtlyewBv6aPdq4D5gfWDx+vwp9WXrA88D7wQWAT4LTAUWHcDj6e8xjKlrGtHHbbtdDuwOrAsEsAPwAjC25fl4lWpX6mL15c8DG9SXfxO4FFgBWBr4FXByz+cS2AB4EFitpYZ1+6jvPODEXv5+E4HV6ramAIfVl60IfABYoq7hIuCXPf4Gh/TzXHY9HxcCSwKbAjNaXi9H1s/16Po5+A5wYR/P5TXAmVQ9mlvU97NzfdnxwIvAu4HhwMnADfVliwJ/BY6oXwvvB17u+Ty01Pxh4Loe2y4ALqmfgzHAPcDBfdy+z8dUX/6R+n4Wq//GN7dc9u36OV29fhxvqa/X9Vz8D9VrfXPgJeCNfdQwt/sZyOvzZKrQukj9s319vQG/3vzxpx0/HS/AH38WtB+6B7X7gHe3XLYrMK0+vSM9glov93Uk8IuW83MLal9oOf9x4Hf16S8CE1ouGwY8BOw4gMfT32Po9kHXy23ndvkvgSNano9XgSVbLp9Q1x5UoW3dlsu2BR7o+VwCbwAeB94BLDKXx3YevQe1A1rOfxU4u4/bbwE81eNvMJCgtmGP+z+3Pj2FOmzV51cFXmF2cM/69BrATGDpluueDJxXnz4euKLlso2Af9an31b/7aPl8ut6Pg8tl32YlqBGFXReAjZq2fbvwNV93L7Px9TLdZerH+Oy9Wv0n8Dm/TyPo1u2TQT27eW6A7mfgbw+v0wVTt/Q4zoDfr354087ftz1Kc2f1ah6L7r8td7Wq4hYv9698mhEPAv8F7BSX9fvxaMtp18AusbOdasjM1+j6gVYfQD3OU+PoT8R8a6IuKHedfQ0VY9P6+N7KjOf76WtUVS9WJPrXU9PA7+rt3eTmVOpAu7xwOMR8ZOImNd6e30eI2KJiPhOvQvtWeBaYLmIGD6P9/9gy+nW53Mt4Bctj3EKVSBbpcftVwP+npnP9bif1r9nz8cwMqrZjasBD2Vm9lHP3KzE7F65vtpu1edjiojhEXFKvVv0WaqQ3NXGSlS9hff1U0tfr/ee9c7tfoC5vj7/m6oX+rJ6t+h4GLTXm/S6GdSk+fMw1QdVlzXrbVB9k+/pLOAuYL3MXAb4HFVv0qDWERFB1Svz0Lzelu6PYcAiYjHg58CpwCqZuRzwv3R/fMtHNX6vZ1tPUPWKbJyZy9U/y2bLJI5WmfnjzHxrXXcCX+mjrN7+Bv05impX19b13+dtXQ9vHu9vjZbTrc/ng8C7Wh7jcpk5MjN7/p0eBlaIiKV73M9A/p6PAKvXr4He6ump52N6gqpHrOdroq+2+3tM/wrsSdUbtSxVDxdUz+cTVLtv1537Q+rXgO5nbq/PzHwuM4/KzHWA9wCf7hqLNg+vN2nQGdSk+XMh8IWIGBXVwP5jgR/Wlz0GrBgRy7Zcf2ngWeAfEbEh8LFBqmMCsHtE7BzVkhpHUe2++uN8PoZ5sSjVuKAZwKsR8S5gl16u96WIWDQitgf2AC6qewD/B/hGRKwMEBGrR8SuPW8cERtExNvrD94XqQLezD5qegxYZx4ew9L1/T1dD4g/7nXe3xfr3rmNgYOAn9bbzwZOioi16scyKiL27HnjzHyQ6m93ckSMjIjNgIOBHw2g7T9RPR+fiIgR9f1v1c/1HwNGRz2pJTNnUr2eToqIpetaP03fr4n+HtPSVK/DJ6l6TP+r5TG+BnwP+HpUEyeGR8S29d91wObhfvp9fUbEHhHxhjrgPkv1HM6cx9ebNOgMatL8ORGYBNwK3Ab8pd5GZt5FFYLur3cLrQb8J1Uvw3NUweSnvd3pvMrMu4EDgDOoehjeA7wnM1+GWevAbT+vj2Eea3gO+BTVh/xTVI/z0h5Xe7S+7GGq0HFY/TwBHE216+mGejfZFVS9Wz0tBpxSP85HqSZBfK6Pss4FNqqf/18O4GF8k2rw+hNUA+R/1+Py04C9o5oReno/93NN/ViuBE7NzMtabn8p1e615+o2tu7jPvaj6oF6GPgFcFxmXj63B1D/zd9PFeyepnpd/JoqMPXmD1TLrzwaEU/U2z5JNWbwfqrxbT+mCkO96e8xXUC12/Qh4M76slb/SfWauxH4O1VP1ev5XJrr/Qzg9bke1WvuH1Rh98zMvJp5e71Jgy66D2OQJC1sIuLPVBMmvt/pWiTNG3vUJGkhExE7RMT/q3d9Hghsxpy9g5IWAB6ZQJIWPhtQ7eJbimo25N6Z+UhnS5L0erjrU5IkqVDu+pQkSSqUQU2SJKlQC+0YtZVWWinHjBnT6TIkSZLmavLkyU9k5hxHY1log9qYMWOYNGlSp8uQJEmaq4j4a2/b3fUpSZJUKIOaJElSoQxqkiRJhVpox6hJkrSgeeWVV5g+fTovvvhip0tRm4wcOZLRo0ezyCKLDOj6BjVJkgoxffp0ll56acaMGUNEdLocDbLM5Mknn2T69OmsvfbaA7qNuz4lSSrEiy++yIorrmhIW0hFBCuuuOI89Zga1CRJKoghbeE2r39fg5okSZolIjjqqKNmnT/11FM5/vjjB+W+P/zhD/Ozn/1sUO6rPxdddBFvfOMb2WmnnbptnzZtGptsskm/t7366qvZY4895qm9HXfcsW1rtzpGTZKkQo0Z/5tBvb9pp+w+1+sstthiXHzxxRxzzDGstNJKg9r+/Jg5cybDhw8f0HXPPfdczjzzzDmC2oLIHjVJkjTLiBEjOPTQQ/nGN74xx2U9e8SWWmopoOqF2mGHHdhnn31Yf/31GT9+PD/60Y/Yaqut2HTTTbnvvvtm3eaKK65g++23Z/311+fXv/41UIWwz3zmM2y55ZZsttlmfOc735l1vzvttBP/+q//yqabbjpHPRdeeCGbbropm2yyCUcffTQAX/7yl7nuuus47LDD+MxnPtPn45w2bRrbb789Y8eOZezYsfzxj3+cddmzzz7L+973PjbaaCMOO+wwXnvtNQAuu+wytt12W8aOHcsHP/hB/vGPf3S7z5kzZ/LhD3+YTTbZhE033bTX53Be2aMmSZK6Ofzww9lss8347Gc/O+Db3HLLLUyZMoUVVliBddZZh0MOOYSJEydy2mmnccYZZ/DNb34TqALSNddcw3333cdOO+3E1KlTueCCC1h22WW58cYbeemll9huu+3YZZddAJg4cSK33377HLMkH374YY4++mgmT57M8ssvzy677MIvf/lLjj32WP7whz9w6qmnMm7cuD7rXXnllbn88ssZOXIk9957L/vtt9+s3ZcTJ07kzjvvZK211mK33Xbj4osvZscdd+TEE0/kiiuuYMkll+QrX/kKX//61zn22GNn3efNN9/MQw89xO233w7A008/PeDnry8GNUmS1M0yyyzDhz70IU4//XQWX3zxAd1myy23ZNVVVwVg3XXXnRW0Nt10U6666qpZ19tnn30YNmwY6623Huussw533XUXl112Gbfeeuus3rpnnnmGe++9l0UXXZStttqq16UsbrzxRnbccUdGjaqOY77//vtz7bXXstdeew2o3ldeeYVPfOIT3HzzzQwfPpx77rln1mVbbbUV66yzDgD77bcf1113HSNHjuTOO+9ku+22A+Dll19m22237Xaf66yzDvfffz+f/OQn2X333Wc9B/PDoCZJkuZw5JFHMnbsWA466KBZ20aMGDFrN2Bm8vLLL8+6bLHFFpt1etiwYbPODxs2jFdffXXWZT1nPUYEmckZZ5zBrrvu2u2yq6++miWXXLLX+jLzdT6yyje+8Q1WWWUVbrnlFl577TVGjhw51xrf+c53cuGFF/Z5n8svvzy33HILv//97/n2t7/NhAkT+N73vjdfdTpGTZIkzWGFFVZgn3324dxzz521bcyYMUyePBmASy65hFdeeWWe7/eiiy7itdde47777uP+++9ngw02YNddd+Wss86adX/33HMPzz//fL/3s/XWW3PNNdfwxBNPMHPmTC688EJ22GGHAdfxzDPPsOqqqzJs2DB+8IMfMHPmzFmXTZw4kQceeIDXXnuNn/70p7z1rW9lm2224frrr2fq1KkAvPDCC9164QCeeOIJXnvtNT7wgQ9wwgkn8Je//GXA9fTFHjVJktSro446im9961uzzn/0ox9lzz33ZKuttmLnnXfus7erPxtssAE77LADjz32GGeffTYjR47kkEMOYdq0aYwdO5bMZNSoUfzyl7/s935WXXVVTj75ZHbaaScyk3e/+93sueeeA67j4x//OB/4wAe46KKL2Gmnnbo9lm233Zbx48dz22238ba3vY33ve99DBs2jPPOO4/99tuPl156CYATTzyR9ddff9btHnroIQ466KBZvY4nn3zyPDwzvYv57Tos1bhx47Jda5pIktQOU6ZM4Y1vfGOny1Cb9fZ3jojJmTnH7Ad3fUqSJBXKoCZJklQog5okSVKhDGqSJBVkYR07rsq8/n0NapIkFWLkyJE8+eSThrWFVGby5JNPdluzbW5cnkOSpEKMHj2a6dOnM2PGjE6XojYZOXIko0ePHvD1DWqSJBVikUUW6fVwSRq63PUpSZJUKHvUJEndjBn/m/m+j2mn7D4IlUiyR02SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgrVtqAWEd+LiMcj4vaWbf8dEXdFxK0R8YuIWK7lsmMiYmpE3B0Ru7Zsf3NE3FZfdnpERLtqliRJKkk7e9TOA3brse1yYJPM3Ay4BzgGICI2AvYFNq5vc2ZEDK9vcxZwKLBe/dPzPiVJkhZKbQtqmXkt8Pce2y7LzFfrszcAo+vTewI/ycyXMvMBYCqwVUSsCiyTmX/KzAQuAPZqV82SJEkl6eQYtY8Av61Prw482HLZ9Hrb6vXpntt7FRGHRsSkiJg0Y8aMQS5XkiSpWR0JahHxeeBV4Eddm3q5WvazvVeZeU5mjsvMcaNGjZr/QiVJkjpoRNMNRsSBwB7AzvXuTKh6ytZoudpo4OF6++hetkuSJC30Gu1Ri4jdgKOB92bmCy0XXQrsGxGLRcTaVJMGJmbmI8BzEbFNPdvzQ8AlTdYsSZLUKW3rUYuIC4EdgZUiYjpwHNUsz8WAy+tVNm7IzMMy846ImADcSbVL9PDMnFnf1ceoZpAuTjWm7bdIkiQNAW0Lapm5Xy+bz+3n+icBJ/WyfRKwySCWJkmStEDwyASSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBVqRKcLkCRJ6suY8b+Z7/uYdsrug1BJZ7StRy0ivhcRj0fE7S3bVoiIyyPi3vr38i2XHRMRUyPi7ojYtWX7myPitvqy0yMi2lWzJElSSdq56/M8YLce28YDV2bmesCV9XkiYiNgX2Dj+jZnRsTw+jZnAYcC69U/Pe9TkiRpodS2oJaZ1wJ/77F5T+D8+vT5wF4t23+SmS9l5gPAVGCriFgVWCYz/5SZCVzQchtJkqSFWtOTCVbJzEcA6t8r19tXBx5sud70etvq9eme23sVEYdGxKSImDRjxoxBLVySJKlppcz67G3cWfazvVeZeU5mjsvMcaNGjRq04iRJkjqh6aD2WL07k/r34/X26cAaLdcbDTxcbx/dy3ZJkqSFXtNB7VLgwPr0gcAlLdv3jYjFImJtqkkDE+vdo89FxDb1bM8PtdxGkiRpoda2ddQi4kJgR2CliJgOHAecAkyIiIOBvwEfBMjMOyJiAnAn8CpweGbOrO/qY1QzSBcHflv/SJIkLfTaFtQyc78+Ltq5j+ufBJzUy/ZJwCaDWJokSdICoZTJBJIkSerBoCZJklQog5okSVKhDGqSJEmFattkAkla0IwZ/5v5vo9pp+w+CJVIUsUeNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCjWi0wVoaBsz/jfzfR/TTtl9ECqRJKk89qhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVKiOBLWI+I+IuCMibo+ICyNiZESsEBGXR8S99e/lW65/TERMjYi7I2LXTtQsSZLUtMaDWkSsDnwKGJeZmwDDgX2B8cCVmbkecGV9nojYqL58Y2A34MyIGN503ZIkSU3r1K7PEcDiETECWAJ4GNgTOL++/Hxgr/r0nsBPMvOlzHwAmAps1Wy5kiRJzWs8qGXmQ8CpwN+AR4BnMvMyYJXMfKS+ziPAyvVNVgcebLmL6fU2SZKkhVondn0uT9VLtjawGrBkRBzQ30162ZZ93PehETEpIibNmDFj/ouVJEnqoE7s+nwH8EBmzsjMV4CLgbcAj0XEqgD178fr608H1mi5/WiqXaVzyMxzMnNcZo4bNWpU2x6AJElSEzoR1P4GbBMRS0READsDU4BLgQPr6xwIXFKfvhTYNyIWi4i1gfWAiQ3XLEmS1LgRTTeYmX+OiJ8BfwFeBW4CzgGWAiZExMFUYe6D9fXviIgJwJ319Q/PzJlN1y1JktS0xoMaQGYeBxzXY/NLVL1rvV3/JOCkdtclSZJUEo9MIEmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoeYpqEXEsIhYpl3FSJIkaba5BrWI+HFELBMRS1IdGP3uiPhM+0uTJEka2gbSo7ZRZj4L7AX8L7Am8G/tLEqSJEkDC2qLRMQiVEHtksx8Bci2ViVJkqQBBbXvANOAJYFrI2It4Nl2FiVJkiQYMbcrZObpwOktm/4aETu1ryRJkiRBP0EtIj49l9t+fZBrkSRJUov+etSWbqwKSZIkzaHPoJaZX2qyEEmSJHU3kHXU1o+IKyPi9vr8ZhHxhfaXJkmSNLQNZNbn/wDHAK8AZOatwL7tLEqSJEkDC2pLZObEHttebUcxkiRJmm0gQe2JiFiXepHbiNgbeKStVUmSJGnu66gBhwPnABtGxEPAA8D+ba1KkiRJA1rw9n7gHfVB2Ydl5nPtL0uSJEkDmfW5YkScDvwfcHVEnBYRK7a/NEmSpKFtIGPUfgLMAD4A7F2f/mk7i5IkSdLAxqitkJkntJw/MSL2alM9Q8qY8b+Zr9tPO2X3QapEkiSVaCA9aldFxL4RMaz+2QeYv4QhSZKkuervoOzPUS3JEcCngR/WFw0D/gEc1/bqJEmShrD+jvXpQdklSZI6aCBj1IiI5YH1gJFd2zLz2nYVJUmSpAEEtYg4BDgCGA3cDGwD/Al4e1srkyRJGuIGMpngCGBL4K+ZuRPwJqolOiRJktRGAwlqL2bmiwARsVhm3gVs0N6yJEmSNJAxatMjYjngl8DlEfEU8HA7i5IkSdLAjvX5vvrk8RFxFbAs8Nu2ViVJkqSBzfrskpnXAETE34A121KRJEmSgHkMai1iUKtQx3gYK0mSyjWQyQS9yUGtQpIkSXPo7xBSn+7rImCp9pQjSZKkLv3t+uzvEFKnDXYhkiRJ6q6/Y31+qclCJEmS1N3rHaMmSZKkNjOoSZIkFarPoBYRR9S/t2uuHEmSJHXpr0ftoPr3GU0UIkmSpO76m/U5JSKmAaMi4taW7QFkZm7W1sokSZKGuP5mfe4XEf8P+D3w3uZKkiRJEszlEFKZ+SiweUQsCqxfb747M19pe2WSJElD3FyP9RkROwAXANOodnuuEREHZua1ba5NkiRpSBvIQdm/DuySmXcDRMT6wIXAm9tZmCRJ0lA3kHXUFukKaQCZeQ+wSPtKkiRJEgysR21SRJwL/KA+vz8wuX0lSZIkCQYW1D4GHA58imqM2rXAme0sSpIkSQMIapn5EtU4ta+3vxxJkiR18VifkiRJhTKoSZIkFcqgJkmSVKjXFdQi4tDBLkSSJEndvd4etRjUKiRJkjSH1xXUMvM7g12IJEmSuptrUIuI0RHxi4iYERGPRcTPI2J0E8VJkiQNZQPpUfs+cCmwKrA68Kt6myRJktpoIEFtVGZ+PzNfrX/OA0a1uS5JkqQhbyBB7YmIOCAihtc/BwBPtrswSZKkoW4gQe0jwD7Ao8AjwN71NkmSJLXRQI71+TfgvQ3UIkmSpBZ9BrWIOLaf22VmntCGeiRJklTrr0ft+V62LQkcDKwIGNQkSZLaqM+glplf6zodEUsDRwAHAT8BvtbX7SRJkjQ4+p1MEBErRMSJwK1UoW5sZh6dmY/PT6MRsVxE/Cwi7oqIKRGxbd3W5RFxb/17+ZbrHxMRUyPi7ojYdX7aliRJWlD0GdQi4r+BG4HngE0z8/jMfGqQ2j0N+F1mbghsDkwBxgNXZuZ6wJX1eSJiI2BfYGNgN+DMiBg+SHVIkiQVq78etaOA1YAvAA9HxLP1z3MR8ezrbTAilgHeBpwLkJkvZ+bTwJ7A+fXVzgf2qk/vCfwkM1/KzAeAqcBWr7d9SZKkBUV/Y9Re1wHbB2AdYAbw/YjYHJhMNf5tlcx8pG77kYhYub7+6sANLbefXm+bQ0QcChwKsOaaa7anekmSpIa0K4z1ZwQwFjgrM99ENbt0fD/Xj162ZW9XzMxzMnNcZo4bNcqjXEmSpAVbJ4LadGB6Zv65Pv8zquD2WESsClD/frzl+mu03H408HBDtUqSJHVM40EtMx8FHoyIDepNOwN3ApcCB9bbDgQuqU9fCuwbEYtFxNrAesDEBkuWJEnqiLkeQqpNPgn8KCIWBe6nWp9tGDAhIg4G/gZ8ECAz74iICVRh7lXg8Myc2ZmyJUmSmtORoJaZNwPjerlo5z6ufxJwUjtrkiRJKk0nxqhJkiRpAAxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVqmNBLSKGR8RNEfHr+vwKEXF5RNxb/16+5brHRMTUiLg7InbtVM2SJElN6mSP2hHAlJbz44ErM3M94Mr6PBGxEbAvsDGwG3BmRAxvuFZJkqTGdSSoRcRoYHfguy2b9wTOr0+fD+zVsv0nmflSZj4ATAW2aqhUSZKkjulUj9o3gc8Cr7VsWyUzHwGof69cb18deLDletPrbXOIiEMjYlJETJoxY8agFy1JktSkxoNaROwBPJ6Zkwd6k162ZW9XzMxzMnNcZo4bNWrU665RkiSpBCM60OZ2wHsj4t3ASGCZiPgh8FhErJqZj0TEqsDj9fWnA2u03H408HCjFUuSJHVA4z1qmXlMZo7OzDFUkwT+kJkHAJcCB9ZXOxC4pD59KbBvRCwWEWsD6wETGy5bkiSpcZ3oUevLKcCEiDgY+BvwQYDMvCMiJgB3Aq8Ch2fmzM6VKUmS1IyOBrXMvBq4uj79JLBzH9c7CTipscIkSZIK4JEJJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQo3odAGSJPU0Zvxv5uv2007ZfZAqkTrLHjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEI1HtQiYo2IuCoipkTEHRFxRL19hYi4PCLurX8v33KbYyJiakTcHRG7Nl2zJElSJ3SiR+1V4KjMfCOwDXB4RGwEjAeuzMz1gCvr89SX7QtsDOwGnBkRwztQtyRJUqNGNN1gZj4CPFKffi4ipgCrA3sCO9ZXOx+4Gji63v6TzHwJeCAipgJbAX9qtnJJkjQUjRn/m/m6/bRTdn/dt+3oGLWIGAO8CfgzsEod4rrC3Mr11VYHHmy52fR6myRJ0kKtY0EtIpYCfg4cmZnP9nfVXrZlH/d5aERMiohJM2bMGIwyJUmSOqYjQS0iFqEKaT/KzIvrzY9FxKr15asCj9fbpwNrtNx8NPBwb/ebmedk5rjMHDdq1Kj2FC9JktSQTsz6DOBcYEpmfr3lokuBA+vTBwKXtGzfNyIWi4i1gfWAiU3VK0mS1CmNTyYAtgP+DbgtIm6ut30OOAWYEBEHA38DPgiQmXdExATgTqoZo4dn5szGq5YkSWpYJ2Z9Xkfv484Adu7jNicBJ7WtKEmSpAJ5ZAJJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSqUQU2SJKlQBjVJkqRCGdQkSZIKZVCTJEkqlEFNkiSpUAY1SZKkQo3odAFSp40Z/5v5vo9pp+w+CJVIktSdPWqSJEmFMqhJkiQVyl2fUgHmd/eru14laeFkUJNUDAOrJHU3ZIOaHwhSd/5PlMHJLeUo4X+i0zX4euw8x6hJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFMqhJkiQVyqAmSZJUKIOaJElSoQxqkiRJhTKoSZIkFcqgJkmSVCiDmiRJUqEMapIkSYUyqEmSJBXKoCZJklQog5okSVKhDGqSJEmFWmCCWkTsFhF3R8TUiBjf6XokSZLabYEIahExHPg28C5gI2C/iNios1VJkiS11wIR1ICtgKmZeX9mvgz8BNizwzVJkiS1VWRmp2uYq4jYG9gtMw+pz/8bsHVmfqLH9Q4FDq3PbgDcPR/NrgQ8MR+3HwzWUEYNnW7fGqyhtBo63b41WENJ7Q9WDWtl5qieG0fM5502JXrZNkfCzMxzgHMGpcGISZk5bjDuyxoW7Bo63b41WENpNXS6fWuwhpLab3cNC8quz+nAGi3nRwMPd6gWSZKkRiwoQe1GYL2IWDsiFgX2BS7tcE2SJElttUDs+szMVyPiE8DvgeHA9zLzjjY3Oyi7UOeTNVQ6XUOn2wdr6GINlU7X0On2wRq6WEPn24c21rBATCaQJEkaihaUXZ+SJElDjkFNkiSpUAY1SZKkQhnU1K+IGBYRy3S6DnVGRIzpZduWHShFHRYRaw9kmzQU1J+N+zTSlpMJuouItYD1MvOKiFgcGJGZzzXQ7gr9XZ6Zf293DS21/Bg4DJgJTAaWBb6emf/dUPvrAtMz86WI2BHYDLggM59uoO0z6GUx5S6Z+al219BSy1cy8+i5bWtzDX8B3pOZD9XndwC+lZmbNlVDp0XEdsDNmfl8RBwAjAVOy8y/NljD+sBZwCqZuUlEbAa8NzNPbLCGv2Tm2B7bJmfmmxtoe2x/l2fmX9pdQ0stI4GDgY2BkS01fKTBGhYFNqR6r7q7PrRiYyLiCOD7wHPAd4E3AeMz87IGa/gg8LvMfC4ivkD1f3liw6+FazPzbW1vx6A2W0R8lOoQVCtk5roRsR5wdmbu3EDbD1D90/V6FIbMXKfdNbTUcnNmbhER+wNvBo4GJmfmZk21D4wDxlAtyXIpsEFmvruBtg/s7/LMPL/dNbTU0tsH461N/R3q9rYEzgTeQ/VG+F9Uwe3BNrf7HP0H5sZ6eSPiVmBzqi8MPwDOBd6fmTs0WMM1wGeA72Tmm+ptt2fmJg20vSFVKPlqXUOXZYDPZObGDdRwVX1yJNV7wy1U75WbAX/OzLe2u4aWWi4C7gL+FfgysD8wJTOPaKj93YGzgfuonoO1gX/PzN820X5dwy2ZuXlE7AocDnwR+H7P96s213BrZm4WEW8FTgZOBT6XmVs3WMMXgX8CPwWe79o+2B0rC8Q6ag06nOoA8H8GyMx7I2LlJhrOzJJ2ISwSEYsAe1H1nrwSEU0m+tfqtfPeB3wzM8+IiJuaaLjJINaXiPgY8HFg3TokdFkauL7JWjLzxoj4FHAZ8CLwzsyc0UC7SwNExJeBR6kCUlB9KC7d7vZ7eDUzMyL2pOpJO3dugb4NlsjMiRHdvse92lDbGwB7AMtRBfYuzwEfbaKAzNwJICJ+AhyambfV5zcB/rOJGlq8ITM/GBF7Zub59R6I3zfY/teAnTJzKszaA/EboLGgxuwOhXdTBbRboseLswEz69+7A2dl5iURcXzDNXT1oh7esi2BQe1YMah191Jmvtz1eouIEfTzrX4wRcSGmXlXX138TXbnAt8BplF9a7223h38bIPtvxIR+wEHMvuDYZEG2yciRlH1JG5E990bb2+g+R9TvemeDIxv2f5cU7vAI+JXdH/tLwE8A5wbEWTme5uoA9i1xzfksyLiz1S9O015LiKOAQ4A3hYRw2n49Qg8UX8gJ0BE7A080kTDmXkJcElEbJuZf2qizX5s2BXSADLz9ojYouEaXql/P10HxUepev+b8nhXSKvdDzzeYPsAkyPiMqrevGMiYmngtYZreCgivgO8A/hKRCxGw+Pum+pgMah1d01EfA5YPCLeSdWr8auG2v401W7Xr/VyWQJNBISqsczTgdNbNv01InZqqn3gIKoxcidl5gP1gOUfNtg+wI+ourN3r2s5EGh7TxJAZj5T7/rbtMlxUD2c2qF2e5pZ74L/CdX/wX7M/ibdlH+h2s11cGY+GhFrAo2M12xxONXK5xtGxEPAA1TBsUlT6/fHMbR8djQ5NguYEhHfpXo/SKrnYEqD7QOcExHLU+3uuxRYCji2wfbviIj/BSZQPQcfBG6MiPcDZObFDdRwMLAFcH9mvhARK1K9bzdpH2A34NTMfDoiVqX7rvm2i4glqD6718zMQ+vhUhtk5q8HtR3HqM0WEcOoXoC7UHXt/h74bg6xJykiPt3L5meoxqnd3Oa2hwPnZ2bTH0I965icmW9uHRMWEdc0PC7pR8Axmfm3ptrspYa1gUcy88X6/OJUA9qnNdT+GOA0YDuqD6XrgSObar+uYUngxcycWQ/q3xD4bWa+MpebtquWYU1McOql7T8C/0c1wWhWWM7MnzdYw0jgY0DXAO5rqXZ7vdhUDZ0WEd/v5+JsIjhHxJcz89iW88OpJnzt3+62e9TxVqrJf9+v94IslZkPNNj+T6n+Hz5UT/JZHPhTZm4xqO0MsQxSvHpsWOsb0dVUA4gb+1Cox1yMY3Zv4u7AjVQfUBdlZlt3O0XE76kGrDc6k6lHDTdk5jZ1LacDDwM/y8x1G6zhD8CWwES6D1RtarcjETEJeEvX36KebXZ9Zg6ZJToiYjKwPbA8cAMwCXihyQ+liFgO+BBz9mY1OQv55sH+AFoQRcQqVJNqVsvMd0XERsC2mXluh0trTEScRzXb9OR6l+NFwF8y8/gGaziO6nNqg8xcPyJWo/p82q7BGiZl5riIuKllks8tmbn5YLbjrs8WUU3DPx5Yi+q5CRqecUk1BX8Rqpl2AP9WbzukwRpWBMZm5j9g1j/Ez6jC42TaPz5oGnB9RFxK94Dy9Ta32+rEiFgWOAo4g2qG23802D7AlxpurzcjWgNzPYZz0XY3GgUtk0L1hfaFiDgYOCMzvxrVzOQm/S9VSLyN5scCdfl1RLw7M/+3Q+339h4NQMPv0edRLU3x+fr8PVTDJNoa1CLis/Vrr9f/jYb/Jw4CflSP3dyJqof5Gw22D/A+qmVB/gKQmQ/XY+Wa9HLdi9Y1dnRd4KXBbsSg1t25VB/G3br2G7ZljzT+h4i4peEa1gRae7NeAdbKzH9GxKC/CHvxcP0zjOZn+HV1469XjzN4huqNqHGZeU0n2u1hRkS8NzMvBahnPj7RQLuTGmhjoCIitqWacXpwvW14wzWMzMzehiQ06QjgcxHxMtX7Q9cX2SYXxC7hPXqlzJxQhxTqGepN1NI1Fq9j/xs9JrudRjXx7Hqq8d1jG5709nI9G7srJC3ZYNtdjgd+B6xRD1XZjjaM1TOodfdMNrgWTR9mRsS6mXkfQESsQ/NvSD8GboiIS+rz7wEurP8R7mx345nZ0Z6keizSe4GmvyF2E93XEluUqqf1+YY/GA+j+ub87fr8g1S9vG3Vc5mUiFgyM5/v6/ptdgRwDPCLzLyj/p+8ai63GWw/iGqdx1/T8o29qVnAdVuNf2nqRQnv0c/Xg+e7AsI2VF/o2iozf1X/7uQSQj0nuz1FNTP+azQ86Q2YUM/6XK7+3/gI8D8Ntk9mXlYPjdiG6ovLEZk56F9kHaPWIiJOofqmfDHd3wybXOl4Z6pu9fup/vBrAQdlZqMfDBExjurbQQDXZWZj3+LqQaGfZc6Vvxt7E4iIk6iOyNBzIcMmvzH2rGkvYKvM/FwH2l6K6v2i0UHsdU/WuVSDhNeMiM2pFvf8eJN1dFpEHA6cBDzN7PDe6LCMiOhax27tzDwhItYAVs3MiQ3WUMJ79Fiq4RCbALcDo4C9M/PWfm84eO2vT7V23Bi67/5tMiQVoV6dYdbkv8y8vOH2r8weC+L3tm2+2zGozRazV79ulU3/A9SDMzegevHdlZlN7G7sWcNwYBW6vxE0MvswqvV5fkr1ZjRraYxs9tBJRbwWeuqa5NBge8sCxzF7css1wJczs+09CHX7fwb2Bi7Nhlfkb6mhhC8O9wFbt+Pb+jzUcBbV+Li3Z+Yb6yUqLmtyYkkJ/5dRHbro98AawAeArYEvNhUW66EwZzPn7NvJTbRf17AY1WMfQ/fPiC83VUNdR+shH5cAhjfxZbKefbwEVc/6jsxeAHgZqvF6bxzM9tz12SLr1a87KWYfv+zWqI5fdlxENH38sk9SfTg/RvVGEFTf4ps6dNGKWa3+fkQ9TuuaqA6h04g6pF7agcGxPet4f8vZYVQznJr+ZvU9ql6DroMP/xtVj+/7+7zFIMvMB6P7oudNDwXoWlNvDxpeU6/FHcALDbfZ09aZOTbqo4Rk5lNNTCxpVcJ7NFUou6gOqu+g2u13FlVga8KrmXlWQ2315RLqJZtow+D5gYiWQz4C6wKrUwXYth/yEfh34EhgNarnoOsN6lng233c5nUzqPUQ1XHUen5zbvJbQtebwFuBXakWHm3yTQCqMTkbZOaTDbbZqmspkkfqv8fDwOimGi9ljBrdD9fzKtVs2D0brmHdzPxAy/kvNTzj8cGIeAuQdSj4FM0vcNrRLw61mcDNdY9S6y6/Jmf6vVJ/iekamzWKDsxALeA9uvXQRWdnQ4cuiogV6pO/ioiPA7+gQ+MVgdGZuVuD7fWmk4d8PA04LSI+mZlntLs9g1qLiDibqjtzJ+C7VLtcGht/USvh+GUP0sDg2H70tjTGkQ3X8MeI+BYdHKOWmU2v9N2bf0bEWzPzOpi1PMI/G2z/MKrZZasD06mOOXp4v7cYfB394lD7Zf3TSadThYOV6zGcewNfaLKAQt6jO3XooslUIbmr9+YzdO9hb3KJkj9GxKbZcjivDujYIR+7ZHUc6k2Y81CDFwxmO45RaxH1KvQtv5cCLs7MXRqs4dfAQ1RvAm+m+lCcmIO8gN5cajiXaozcb+j+ja2Rdcwi4nyq2TNP1+dXoDpMSGOHqilkLMxoqqDatSr/dVTPy/QGa9gcuIBqYgVUs7wObGrgdAkiYg+qFfnXYPYXhy91LVnSYB2LAuvXZ+/OzhwZYUOqXUsBXJmZjfZuFvIevQTVoYtuq3txVqU63NtlDbW/D9XwmGcj4ovAWOCEhofH3Am8gepQZi8xe6mWpobHEBFfpZpc8yHgk1SHfLwzMz/f3+0GuYbjqMaobUS11uG7qCbf7T2Y7dij1l1XT8ELUa1y/CTVQWeb1PHjlwF/q38WrX+atllXSIOqSz8i3tRkAYWMhfk+1VIpH6zPH1Bve2e7G47uhxG7AOhao+h5qi8RbQ1qUcjinlHImnoRsSNwPtXu76Bat+nAzLy24VIeowqtI6iOidz02lldh4rqeo/+Ow2/R2fmC1SzTrvOPwI80mAJX8hqHbe3Ur0XND1GDqpA0mlHUy0EfxvVmLH/peplbdLewObATZl5UFRHrRj0Ggxq3f06qkO1/DfVasdJw3/41jeBiDg0M8+h2TeBjq9jBgyLiOUz8ymY1aPW+Gu1gLEwozKz9bh+50XEkQ213bVm1gZUh7G6hCogHEB1fMV2O5rqCBj3UfXidURB4xW/BuySmXfDrCUaLqTqdW9ERJwAfJjqbzJriRCaXTvrV728Rze6dlYBOjJGrlVm/hWgHhM2ci5XH3RRHZf71nr2dyf//i9m5msR8WpELAM8Tht2QRvUWmTmCfXJn9e7IEc2tQxBHw4DzmmqsYj4ZmYeGRG/ovdejKaOMfk1qjEQP6vr2IdqDanGFDIW5omIOIDqAxlgP6pe3rbrCuv1Uilju6a81x8IFzVQwmP11PuD6FAvVouOj1cEFukKaXXb90R1XOAm7UM1uaRjx+AF7gJmZubPozrG5lg6P3avaZ0aIzdL/eXla1SzHh+nWu9zCtUX27arw9EtEbFmU8tG9eHG+ovD/1CNIfwHbficcIwacyyDMIfMvLi/y9slWg702lB7b87MyRGxQ2+XZ4OHNKrfhN/O7LEwbT8iQo/2SxgLsybwLWBbqsD6R+BTTb4xRcRdwOZZr+VXfyjckpkbtrndrjEn61CN2Zx1Ec0v9No1XrHrzbKrhibHK36vbv8H9ab9qY7D2tiEk4j4OfCxzHy8qTZ7qaHr//GtVAdG/xrwucxscrdfR3V6jFxdwy1U789XZOabImInYL/MPLTBGv5A1ds/ke5foJrqUCAifkC1h+H/qHbLL9OO8bsGNSAivt/PxdnkIPZWETG6yYHjmi0i/pyZW0fEDVRrhj0J3J6Z6zVYw/nAkT12ATc9qeLzVD0pv6AKCu8DfpqZJzfU/lmZ+bEm2uqnhqPoPtsuqdZLmpSZNzdUw2JUs13fWtdxLXBmNrgYdlRHK7mEal291klGTX4w3lQHg5OpgsqPm/5CK4iISZk5rg5sb6p7uCZm5lYN1jCR7uO3A/hKk6E9It5O9T+5PdWXypuBa7NavmPw2jGolaUejPhfwGqZ+a66Z2nbzDy3gbZvo5/pzU3O6Om0ejbVGVQz3L5NPRYmM49tsIY5PoA68aEU1SFztq/PXpuZNzXZfqdFxI+pFhu+lOrDYHfgRmBD4KLM/GoHy2tMRNxBdRDu22hZP63hnvaOz4oXRMQVwF7AycBKVLs/x2Xmdg3W8JfMHNtj261Nf07VE462pBqicRjwz8He42BQaxHVgXaPo0rIXcshfDkbXPg1In5LNbPv85m5eVRrw9yUmZs20PZa9cmudapad7O80PBA+mLUvRmNj1esv63u2KNH7ZomXguaLSJ+D3wgM/9Rn18K+BlV7+LkzNyogRq2A46nGgvUesieJncBX5OZvQ6LaLCGju/2E0TE16h6s4ZRfT4sSzVE4uAG2v4Ys4dF3Ndy0dLA9Zl5QLtraKnlSqoZ8X+i2v15XTuGBhjUWkTE5VS7FH5Yb9qf6oPyHQ3WcGNmbtnacxIRN2fmFg3WcH3Pb0a9bVuYRXUst4/TPbSflZkv9nvDwa3hQ8AxVKFg1qSKzPxBvzfUoIqIKVQfQi/X5xcDbs7qeJeN9HDWYwX/gzmP79jkl8ivU+3yvJQOHRBdZehkb1ZUi6EvT9WbN77louey2aMzEBHfoOrZfQm4nio//CkzB3VRcGd9drdCy8xPqFbI36vhGp6ve/a6DtOyDc0fJWDJ6L4a/VuYvY7WUHEB8BzV7k+oZlz+gNlrmrVdZl4QEZOYPani/U1PqhBQrWV3Q0RcUp9/D3BhRCwJNPX3eCYzf9tQW33pCqTbtGxrenkOdVBLb9a6EdE6aH5pqqDSdvWejWeo3pM7KjP/A2b1sh9EtTfs/wGLDWY79qi1iIhTgUnAhHrT3sDGmXlcgzWMpQoHm1AN2h0F7N2OmST91PBmqoNxd61G/zTwkaH0zTkibuk57qW3bRoa6v+JroH812XmpIba7eq12AcYTrXGor1Z6oiSerNKEBGfoBq/+2bgr9QzQDPzD4PajkFttoh4jqrnqGvXwnBmT/vNzFymze0Ppzro9BlUC40GHTpUTF3PMlSvkU6uJdcREXEe1WKSN9Tnt6Y6dNLHO1qYhpTo/VBmXZpeIqRjE52kEkXEZ6jC2eTMfLVt7RjUKhERwBrZ2cXziIirM3PHDrX96f4uz4aO9VmCelzSBlSH0gJYk2pBx9do+Jh2Ugk6OdFJGsoco1bLzIyIX9DgIVn6cH10bhX0ped+lSFjt04XIPUmIn6dmXt0oOmVsjrG5DEAmflqRMyc240kzR+DWnc3RMSWmXljB2t4S/27dSmMRgbsZueP8VmM7ONYdp3ucZWA1TvUbgkTnaQhx6DW3U7Av0fEX6l6s7oOFdPYbq7M7NhxDSPis5n51Yg4g96P9fmpDpTVEdHhY9lJ/ejUgsNHUS3NsW5EXE890alDtUhDhkGtu3d1ugCAiNidKhC09uQ0sdjslPp3IzPaCncC1TIE3Y5l1+GaNIRFxOLAmtmhQ9rl7OMAd3yikzSUGNSoZjdm5rNU62Z1upazgSWoeve+S/WNdWITbWfmr+rf5zfRXuFeycwnI2JYRAzLzKsi4iudLkpDU0S8BzgVWBRYOyK2oDpqSpPH2byFauzsTzPzvrldX9LgMKhVfgzsQbXqd+suv6jPN3aYFuAtmblZvcrzl+pDdVzcYPtdSwL0tutzKC1s+XS9iOG1wI8i4nGgbdOvpbk4HtgKuBogM2+OiDEN1/Be4F+ACRHxGlVom+C4Tam9DGpA1wyqzFy7Pp7ierTsdmxY16EnXoiI1YAngbUbruE/W06PBD7A0AspewIvUh22p+tYdkPyWKcqwquZ+Uy1ilBn1BNsvgp8NSLWA74IfIVqvUlJbWJQaxERhwBHAKOBm6nGKP0R2LnBMn4dEctRvSFOrrd9t8H2yczJPTZdHxHXNFlDp2Xm8y1n3RWsTrs9Iv4VGF6HpE9RvTc1qu7F24eqZ20m8Nmma5CGGhe8bRERtwFbAjdk5hYRsSHwpcz8lwZrWBz4GNVhKRL4P5o/GPgKLWeHAeOA0zJzg6Zq6LSIeD9Vb8HKVLvAu2YAt/XoFFJvImIJ4PPALlSvxd8DJzT8vvBnYBHgIqpxavc31bY0lBnUWkTEjZm5ZUTcDGydmS9FxM2ZuUWDNUygmtTww3rTfsBymblPgzU8wOwxaq8C06gGLl/XVA2dFhFTgfdk5pS5XlkaAiJiw8y8q9N1SEONuz67m17vdvwlcHlEPAU83HANG/Q48PdV9WyrJm0EfJzqINRdvXpDbcmOxwxp6rSI+BW9TOzp0uSsz8y8q4NLB0lDlkGtRWa+rz55fD3zcVngdw2XcVNEbNPjYODXN1zD+cCzwOn1+f2AHwAfbLiOxtW7PAEmRcRPqUL7S12XZ2ajM3A15J3a6QK6dHLpIGkoc9dnIerxcUk1BqTrYOBJtSL+nZm5SYO13NKjV6/XbQujiPh+fTKpxgK1yk4tNip1Wr1k0GYtv5cCLs7MXTpdm7Qws0etHJ04yHJfSujV64jMPAggIs4HjsjMp+vzy1MdUkpqTERMyMx9Wr7IzbqIhg9vRxlLB0lDjkGtEF0HAe+kHr16H4qIbr16naytAzbrCmkAmflURLypg/VoaDqi/l3CF7mOLx0kDUXu+tQsEbFWf5eXECabUk/g2DEzn6rPrwBck5mbdrYyDVUR8f+ojk6QwI2Z+WjD7Xd86SBpKDKoSb2IiA8BxwA/o/pQ2gc4KTN/0NHCNCTVi3EfC/yBarfnDlRL5nyvwRo6vnSQNBQZ1KQ+RMRGwNupPhivzMyhtvtXhYiIu6mOA/xkfX5F4I9NLkI9lCcZSZ3kGDWpD3UwM5ypBNOperO6PAc82HANQ3aSkdRJBjVJKlREfLo++RDw54i4hGpX/J40v4bZ1syeZASwJjClaxJSwzNQpSHDoCZJ5Vq6/n1f/dPlkg7UslsH2pSGPMeoSdICIiKWpuq9+kena5HUjGGdLkCS1L+I2CQibgJuB+6IiMkRsXGn65LUfgY1SSrfOcCnM3OtzFwLOAr4nw7XJKkBBjVJKt+SmXlV15nMvBpYsnPlSGqKkwkkqXz3R8QXga4Flw8AHuhgPZIaYo+aJJXvI8Ao4OfAxcBKwIc7WZCkZhjUJKl86wJrUL1nLwLsDFzb0YokNcLlOSSpcPUhpP6Tatbna13bM/OvHStKUiMcoyZJ5ZuRmb/qdBGSmmePmiQVLiJ2BvYDrgRe6tqemRd3rChJjbBHTZLKdxCwIdX4tK5dn0k1sUDSQsygJknl2zwzN+10EZKa56xPSSrfDRGxUaeLkNQ8x6hJUuEiYgrVEh0PUI1RC6qDs2/W0cIktZ1BTZIKFxFr9bbd5TmkhZ9BTZIkqVCOUZMkSSqUQU2SJKlQBjVJC5SIWDEibq5/Ho2Ih1rOL9rjukdGxBIDuM+rI2JcL9sXiYhTIuLeiLg9IiZGxLvqy6ZFxEqD98gkaU6uoyZpgZKZTwJbAETE8cA/MvPUPq5+JPBD4IXX2dwJwKrAJpn5UkSsAuzwOu9LkuaZPWqSFngRsXNE3BQRt0XE9yJisYj4FLAacFVEXFVf76yImBQRd0TEl+Zyn0sAHwU+mZkvAWTmY5k5oZfr/jIiJtf3e2i9bXhEnFf3xN0WEf9Rb/9URNwZEbdGxE/qbUvWdd9YP4496+0b1714N9fXX2/wnjVJCwJ71CQt6EYC5wE7Z+Y9EXEB8LHM/GZEfBrYKTOfqK/7+cz8e0QMB66MiM0y89Y+7vcNwN8y89kB1PCR+n4XB26MiJ8DY4DVM3MTgIhYrr7ueGDtuoeua9vngT9k5kfqbRMj4grgMOC0zPxRvVt3+ACfE0kLCXvUJC3ohgMPZOY99fnzgbf1cd19IuIvwE3AxsBgrfb/qYi4BbgBWANYD7gfWCcizoiI3YCuwHcr8KOIOAB4td62CzA+Im4GrqYKn2sCfwI+FxFHA2tl5j8HqV5JCwiDmqQF3fMDuVJErA38J1XP22bAb6gCUV+mAmtGxNJzud8dgXcA22bm5lQhcGRmPgVsThW8Dge+W99kd+DbwJuByRExgupIAx/IzC3qnzUzc0pm/hh4L/BP4PcR8faBPFZJCw+DmqQF3UhgTES8oT7/b8A19enngK6gtQxVqHumnhTwrv7uNDNfAM4FTu+aTRoRq9Y9Ya2WBZ7KzBciYkNgm/q6KwHDMvPnwBeBsRExDFgjM68CPgssBywF/B74ZEREfds31b/XAe7PzNOBSwEPGSUNMY5Rk7SgexE4CLio7p26ETi7vuwc4LcR8Uhm7hQRNwF3UO2WvH4A9/0F4ETgzoh4kSroHdvjOr8DDouIW4G7qXZ/AqwOfL8OZwDHUO2m/WFELEvVi/aNzHw6Ik4AvgncWoe1acAewL8AB0TEK8CjwJcH+JxIWkh4CClJkqRCuetTkiSpUAY1SZKkQhnUJEmSCmVQkyRJKpRBTZIkqVAGNUmSpEIZ1CRJkgplUJMkSSrU/wfePvRlvbZQIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = data.sum(axis=\"rows\")\n",
    "df = pd.DataFrame(result,columns=['Number of labels'])   #Convert into Data Frame\n",
    "#Drop the first row\n",
    "df.drop(index=df.index[0], \n",
    "        axis=0, \n",
    "        inplace=True)\n",
    "print(df)\n",
    "\n",
    "\n",
    "df.plot.bar(figsize=(10,10))\n",
    "plt.xlabel(\"Total Classes\")\n",
    "plt.ylabel(\"No. of Labels\")\n",
    "plt.title(\"Total no. of labels that belong to each class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b3e66-0f3f-4d5c-a749-3eaee0efec8f",
   "metadata": {},
   "source": [
    "## Designing Data Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b4a6bed-5835-4132-b310-a77f67f2793c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:17.663865Z",
     "iopub.status.busy": "2022-07-15T17:07:17.663520Z",
     "iopub.status.idle": "2022-07-15T17:07:17.673906Z",
     "shell.execute_reply": "2022-07-15T17:07:17.672983Z",
     "shell.execute_reply.started": "2022-07-15T17:07:17.663826Z"
    }
   },
   "outputs": [],
   "source": [
    "class UCMerced(Dataset):\n",
    "    def __init__(self, root_dir, img_transform=None, multilabel=True):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.images_path = os.path.join(root_dir, \"Images\")\n",
    "        self.class_names = sorted(\n",
    "            [cl for cl in os.listdir(self.images_path) if not cl.startswith(\".\")]\n",
    "        )\n",
    "        self.img_paths, self.img_labels = self.init_dataset()\n",
    "        self.img_transform = img_transform\n",
    "\n",
    "        if multilabel:\n",
    "            self.img_labels = self.read_multilabels()  # important for loss calculation\n",
    "            self.img_labels = self.img_labels.astype(float)\n",
    "\n",
    "    def init_dataset(self):\n",
    "        img_paths, img_labels = [], []\n",
    "        for cl_id, cl_name in enumerate(self.class_names):\n",
    "            cl_path = os.path.join(self.images_path, cl_name)\n",
    "\n",
    "            for img in sorted(os.listdir(cl_path)):\n",
    "                img_path = os.path.join(cl_path, img)\n",
    "                img_paths.append(img_path)\n",
    "                img_labels.append(cl_id)\n",
    "\n",
    "        return img_paths, img_labels\n",
    "\n",
    "    def read_multilabels(self):\n",
    "        label = pd.read_excel(\"./Hw3_data/UCMerced_LandUse/multilabels/LandUse_Multilabeled.xlsx\")\n",
    "        label = label.set_index(\"IMAGE\\LABEL\")\n",
    "        label = np.array(label)\n",
    "        return label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(img)\n",
    "\n",
    "        return dict(img=img, label=label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeff5703-931e-45ca-b2a0-7e36913630dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:18.072983Z",
     "iopub.status.busy": "2022-07-15T17:07:18.072483Z",
     "iopub.status.idle": "2022-07-15T17:07:18.079849Z",
     "shell.execute_reply": "2022-07-15T17:07:18.078447Z",
     "shell.execute_reply.started": "2022-07-15T17:07:18.072955Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetricTracker(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af72c425-858b-4ac9-a29b-b134e9c8c97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:18.447519Z",
     "iopub.status.busy": "2022-07-15T17:07:18.447094Z",
     "iopub.status.idle": "2022-07-15T17:07:18.452987Z",
     "shell.execute_reply": "2022-07-15T17:07:18.451896Z",
     "shell.execute_reply.started": "2022-07-15T17:07:18.447491Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_device(cuda_int):\n",
    "    \"\"\"Get Cuda-Device. If cuda_int < 0 compute on CPU.\"\"\"\n",
    "    if cuda_int < 0:\n",
    "        print(\"Computation on CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"Computation on CUDA GPU device {}\".format(cuda_int))\n",
    "        device = torch.device(\"cuda:{}\".format(cuda_int))\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba7d50f-1d3e-4f4e-9a27-7adda55aa865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:20.010858Z",
     "iopub.status.busy": "2022-07-15T17:07:20.010521Z",
     "iopub.status.idle": "2022-07-15T17:07:20.018899Z",
     "shell.execute_reply": "2022-07-15T17:07:20.017971Z",
     "shell.execute_reply.started": "2022-07-15T17:07:20.010832Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets ,models , transforms\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader ,random_split\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.optim import Adam\n",
    "\n",
    "def get_dataset(root_dir, tr_transform,seed=1, multilabel=True):\n",
    "    valid_no = int(2100*0.1)\n",
    "    train_no = int(2100*0.7) \n",
    "    test_no = int(2100*0.2)\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ---------\n",
    "    root_dir     : path to UCMerced Dataset\n",
    "    tr_transform : transformation for training data\n",
    "    te_transform : transformation for training data\n",
    "    set_sizes    : list of percentage of either train-test or train-val-test (sum to 100)\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    sets for train and test, optionally also val if len(set_sizes)==3\n",
    "    \"\"\"\n",
    "    ucm_dataset_tr = UCMerced(root_dir, img_transform=tr_transform, multilabel=multilabel)\n",
    "    #ucm_dataset_te = UCMerced(root_dir, img_transform=te_transform, multilabel=multilabel)\n",
    "    \n",
    "    trainset ,validset, testset  = random_split(ucm_dataset_tr, [train_no, valid_no, test_no])\n",
    "    \n",
    "    return trainset ,validset, testset\n",
    "    \n",
    "    \n",
    "    #idx_list = split_ucm_indices(set_sizes, seed=seed)\n",
    "\n",
    "   # train_set = Subset(ucm_dataset_tr, idx_list[0])\n",
    "    #test_set = Subset(ucm_dataset_te, idx_list[-1])\n",
    "\n",
    "    #if len(idx_list) > 2:\n",
    "     #   val_set = Subset(ucm_dataset_te, idx_list[1])\n",
    "      #  return train_set, val_set, test_set\n",
    "    #else:\n",
    "     #   return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa9e27cd-697e-494a-b93f-0f3ec05aaec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:24.863445Z",
     "iopub.status.busy": "2022-07-15T17:07:24.862797Z",
     "iopub.status.idle": "2022-07-15T17:07:24.870513Z",
     "shell.execute_reply": "2022-07-15T17:07:24.869429Z",
     "shell.execute_reply.started": "2022-07-15T17:07:24.863398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create class labels\n",
    "classLabels = [\"airplane\", \"bare-soil\", \"buildings\", \"cars\",\"chaparral\", \"court\", \"dock\", \"field\", \"grass\", \"mobile-home\",\"pavement\",\"sand\", \"sea\",\"ship\",\n",
    "               \"tanks\", \"trees\", \"water\"]\n",
    "\n",
    "import os\n",
    "os.chdir(\"/notebooks\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe22e1-0d8c-415d-a0f4-c84b1c8ff3e0",
   "metadata": {},
   "source": [
    "# Training Design\n",
    "\n",
    "In this part, we will be creating a CNN. In order to perform CNN, we had to perform the following tasks: \n",
    "1) Divide our data into training, test and validation. We use 70% data for training, 20% for testing and 10% for validation. \n",
    "2) We create the Convolution layer. In this case we use the pytorch pretrained resnet 18 model \n",
    "3) For criterion, we use a BCEWithLogitsLoss function. This is due to the fact that we want to perform multilabel classification \n",
    "4) For optimizer, we use Adam optimizer. It is the same as stochastic gradient descent \n",
    "5) We create a dense layer that used for training the model \n",
    "6) We evaluate the model in order to check whether the model is overfitting or underfitting \n",
    "7) Test the model for unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb00ebf-e8d4-40b4-8a64-f9747e191565",
   "metadata": {},
   "source": [
    "\n",
    "In the first part, we divide our dataset into training test and validation. We provide 70% data to training, 10% to validation and 20% to testing. We already splitted the data randomly in the function get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06bcca3a-c413-46fc-ba33-bd03930c0e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:29.699657Z",
     "iopub.status.busy": "2022-07-15T17:07:29.699287Z",
     "iopub.status.idle": "2022-07-15T17:07:29.704494Z",
     "shell.execute_reply": "2022-07-15T17:07:29.703565Z",
     "shell.execute_reply.started": "2022-07-15T17:07:29.699632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation on CUDA GPU device 0\n"
     ]
    }
   ],
   "source": [
    "#Choose our device\n",
    "cuda_device = get_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53f2f9ad-276e-4d8c-a4a3-8f9a2d0809cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:32.453584Z",
     "iopub.status.busy": "2022-07-15T17:07:32.453232Z",
     "iopub.status.idle": "2022-07-15T17:07:32.458805Z",
     "shell.execute_reply": "2022-07-15T17:07:32.457647Z",
     "shell.execute_reply.started": "2022-07-15T17:07:32.453558Z"
    }
   },
   "outputs": [],
   "source": [
    "#Choose our parameter\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b104c9d-3e74-474d-ac16-f74251462c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:32.798931Z",
     "iopub.status.busy": "2022-07-15T17:07:32.798532Z",
     "iopub.status.idle": "2022-07-15T17:07:32.804986Z",
     "shell.execute_reply": "2022-07-15T17:07:32.804203Z",
     "shell.execute_reply.started": "2022-07-15T17:07:32.798876Z"
    }
   },
   "outputs": [],
   "source": [
    "ucm_mean = [0.595425, 0.3518577, 0.3225522]\n",
    "ucm_std = [0.19303136, 0.12492529, 0.10577361]\n",
    "\n",
    "#So we resize the images so all image have same size\n",
    "#This is how we transform all images\n",
    "\n",
    "#We do it for both training and testing data\n",
    "#For further understanding, pls refer to the following webste: https://www.programcreek.com/python/example/104832/torchvision.transforms.Compose\n",
    "\n",
    "tr_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=ucm_mean, std=ucm_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "te_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=ucm_mean, std=ucm_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d0bb8c9-dee6-4579-9459-023ac17f47e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:33.453335Z",
     "iopub.status.busy": "2022-07-15T17:07:33.452942Z",
     "iopub.status.idle": "2022-07-15T17:07:34.154614Z",
     "shell.execute_reply": "2022-07-15T17:07:34.153679Z",
     "shell.execute_reply.started": "2022-07-15T17:07:33.453294Z"
    }
   },
   "outputs": [],
   "source": [
    "#Split data into train, validation and test\n",
    "trainset, valset, testset = get_dataset(\n",
    "    \"./Hw3_data/UCMerced_LandUse\",\n",
    "    tr_transform=tr_transform,\n",
    "    multilabel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b6638c1-aa85-4824-b54e-8ce639983b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:37.367279Z",
     "iopub.status.busy": "2022-07-15T17:07:37.366866Z",
     "iopub.status.idle": "2022-07-15T17:07:37.373184Z",
     "shell.execute_reply": "2022-07-15T17:07:37.371996Z",
     "shell.execute_reply.started": "2022-07-15T17:07:37.367240Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26768bb9-53c5-4c31-9c5a-b3708a76ecb5",
   "metadata": {},
   "source": [
    "## Define our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ea52a99-0770-43f6-b608-906da0b58ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:39.828398Z",
     "iopub.status.busy": "2022-07-15T17:07:39.828020Z",
     "iopub.status.idle": "2022-07-15T17:07:44.197625Z",
     "shell.execute_reply": "2022-07-15T17:07:44.196678Z",
     "shell.execute_reply.started": "2022-07-15T17:07:39.828372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(512, 17) #21 - number of classes\n",
    "model.to(cuda_device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77159ed1-9352-4ab3-b567-957f802b93a2",
   "metadata": {},
   "source": [
    "## Define our criterion and gradient descent as stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54eb38b1-ee40-40b2-afc7-2aeaf4e8be0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:07:48.211117Z",
     "iopub.status.busy": "2022-07-15T17:07:48.210685Z",
     "iopub.status.idle": "2022-07-15T17:07:48.217683Z",
     "shell.execute_reply": "2022-07-15T17:07:48.216716Z",
     "shell.execute_reply.started": "2022-07-15T17:07:48.211072Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.BCEWithLogitsLoss().to(cuda_device)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fd695f-a16d-4ef1-a1c9-11f11ed56960",
   "metadata": {},
   "source": [
    "## Define functions for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8d3a7b2-bf97-4df9-ac84-be19841ff20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T19:21:16.365144Z",
     "iopub.status.busy": "2022-07-15T19:21:16.364771Z",
     "iopub.status.idle": "2022-07-15T19:21:16.373666Z",
     "shell.execute_reply": "2022-07-15T19:21:16.372416Z",
     "shell.execute_reply.started": "2022-07-15T19:21:16.365096Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, epochs, device, early_stop=False):\n",
    "    train_losses, val_losses = [], []\n",
    "    accuracy_scores = []\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_acc = 0\n",
    "    best_epoch = 1\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        print(\"Epoch {}/{}\".format(epoch, epochs))\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, report, _ = val_epoch(model, val_loader, criterion, device)\n",
    "        overall_acc = report[\"accuracy\"]\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        accuracy_scores.append(overall_acc)\n",
    "\n",
    "        if best_acc < overall_acc:\n",
    "            best_acc = overall_acc\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "        if epoch - best_epoch > 10 and early_stop:\n",
    "            break\n",
    "\n",
    "    return best_model, train_losses, val_losses, accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "472ff0aa-cc35-41f4-8584-a94042d12026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T19:21:16.719213Z",
     "iopub.status.busy": "2022-07-15T19:21:16.718750Z",
     "iopub.status.idle": "2022-07-15T19:21:16.727807Z",
     "shell.execute_reply": "2022-07-15T19:21:16.726771Z",
     "shell.execute_reply.started": "2022-07-15T19:21:16.719186Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.train()\n",
    "\n",
    "    tqdm_bar = tqdm(train_loader, desc=\"Training: \")\n",
    "    for batch in tqdm_bar:\n",
    "\n",
    "        images = batch[\"img\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        batch_size = images.size(0)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        #loss = criterion(logits, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        loss_tracker.update(loss.item(), batch_size)\n",
    "\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        #batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "        #acc_tracker.update(batch_acc, batch_size)\n",
    "        tqdm_bar.set_postfix(loss=loss_tracker.avg, accuracy=acc_tracker.avg)\n",
    "        tqdm_bar.set_postfix(loss=loss_tracker.avg)\n",
    "\n",
    "    return loss_tracker.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0321b5b-865b-445c-b00a-46f0eef283c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9f3903f7-15aa-4e4a-9d2d-f8a9477debdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T19:27:43.808253Z",
     "iopub.status.busy": "2022-07-15T19:27:43.807904Z",
     "iopub.status.idle": "2022-07-15T19:27:43.820248Z",
     "shell.execute_reply": "2022-07-15T19:27:43.818830Z",
     "shell.execute_reply.started": "2022-07-15T19:27:43.808225Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_prediction_normalize = []\n",
    "    y_pred_segmented = []\n",
    "    classLabels = [\"airplane\", \"bare-soil\", \"buildings\", \"cars\",\"chaparral\", \"court\", \"dock\", \"field\", \"grass\", \"mobile-home\",\"pavement\",\"sand\", \"sea\",\"ship\",\n",
    "               \"tanks\", \"trees\", \"water\"]\n",
    "    \n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_bar = tqdm(val_loader, desc=\"Validation: \")\n",
    "        for batch in tqdm_bar:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            logits = model(images)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss_tracker.update(loss.item(), batch_size)\n",
    "\n",
    "            #_, predicted = torch.max(probs.data, 1)\n",
    "            predicted_prob, predicted_labels = torch.topk(probs.data, 17) #Find values fo all classes\n",
    "           # batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "            #acc_tracker.update(batch_acc, batch_size)\n",
    "            acc_tracker.update(batch_size)\n",
    "\n",
    "            y_pred += predicted_labels.tolist()\n",
    "            y_true += labels.tolist()\n",
    "            tqdm_bar.set_postfix(loss=loss_tracker.avg, accuracy=acc_tracker.avg)\n",
    "            \n",
    "            y_pred_arr = np.array(y_pred)\n",
    "            y_true_arr = np.array(y_true)\n",
    "            \n",
    "            # We can normalize the y_prediction values between 0 & 1\n",
    "\n",
    "            \n",
    "            y_prediction_normalize  = normalization(y_pred_arr)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            min_val = np.amin(y_pred_arr)\n",
    "            max_val = np.amax(y_pred_arr)\n",
    "            for i in y_pred_arr:\n",
    "                for j in i:\n",
    "                    z = ((y_pred_arr[j] - min_val)/ (max_val -min_val))\n",
    "                y_prediction_normalize.append(z)\n",
    "\n",
    "            y_prediction_normalize = np.array(y_prediction_normalize)\n",
    "            print(y_prediction_normalize)\n",
    "            print(y_prediction_normalize.shape)\n",
    "            \n",
    "           \"\"\"         \n",
    "            \n",
    "            \n",
    "            # Now we perform segmentation. Values > 0.5 -> 1 while other -> 0\n",
    "            \n",
    "            y_pred_segmented = np.where(y_prediction_normalize > 0.5, 1, 0) \n",
    "            y_pred_segmented = np.array(y_pred_segmented)\n",
    "            \n",
    "    print(y_pred_segmented)\n",
    "    print(y_pred_segmented.shape)\n",
    "      \n",
    "     \n",
    "    #Classfication_report and Multilabel confusion matrix\n",
    "    \n",
    "    report = classification_report(y_true, y_pred_segmented,target_names=classLabels)\n",
    "    #report = classification_report(y_true, y_pred_segmented, zero_division=0, output_dict=True)\n",
    "    conf_mat = multilabel_confusion_matrix(y_true, y_pred_segmented)\n",
    "        \n",
    "    return loss_tracker.avg, report, conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4e9570c1-5452-4638-bead-b77061f6d648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T19:27:45.311500Z",
     "iopub.status.busy": "2022-07-15T19:27:45.311085Z",
     "iopub.status.idle": "2022-07-15T19:27:45.316117Z",
     "shell.execute_reply": "2022-07-15T19:27:45.315148Z",
     "shell.execute_reply.started": "2022-07-15T19:27:45.311472Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e17a9ee0-48c6-43df-9f7c-391be9c4325c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T19:27:46.352503Z",
     "iopub.status.busy": "2022-07-15T19:27:46.351812Z",
     "iopub.status.idle": "2022-07-15T19:27:52.499177Z",
     "shell.execute_reply": "2022-07-15T19:27:52.495851Z",
     "shell.execute_reply.started": "2022-07-15T19:27:46.352475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea8e0fe495b4118bda4da33ff13b56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6aff969006a4f13aee6a22cb186af39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 1 1 1]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 1 0 1]\n",
      " [0 1 1 ... 0 1 0]\n",
      " [0 1 0 ... 1 1 0]]\n",
      "(210, 17)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model, train_losses, val_losses, accuracy_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m eval_accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy_scores)\n",
      "Input \u001b[0;32mIn [117]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, epochs, device, early_stop)\u001b[0m\n\u001b[1;32m     13\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[1;32m     14\u001b[0m val_loss, report, _ \u001b[38;5;241m=\u001b[39m val_epoch(model, val_loader, criterion, device)\n\u001b[0;32m---> 15\u001b[0m overall_acc \u001b[38;5;241m=\u001b[39m \u001b[43mreport\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     18\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "best_model, train_losses, val_losses, accuracy_scores = train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    epochs=3,\n",
    "    device=cuda_device,\n",
    ")\n",
    "eval_accuracies.append(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6fae4c3b-fa64-4335-a8a6-ee99f5c688ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T18:41:38.595892Z",
     "iopub.status.busy": "2022-07-15T18:41:38.595532Z",
     "iopub.status.idle": "2022-07-15T18:41:38.604492Z",
     "shell.execute_reply": "2022-07-15T18:41:38.603407Z",
     "shell.execute_reply.started": "2022-07-15T18:41:38.595865Z"
    }
   },
   "outputs": [],
   "source": [
    "#Testing val_epoch to test results\n",
    "#Check the following link: https://discuss.pytorch.org/t/how-to-extract-probabilities/2720/9\n",
    "\n",
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_prediction_normalize = []\n",
    "    y_pred_segmented=[]\n",
    "    classLabels = [\"airplane\", \"bare-soil\", \"buildings\", \"cars\",\"chaparral\", \"court\", \"dock\", \"field\", \"grass\", \"mobile-home\",\"pavement\",\"sand\", \"sea\",\"ship\",\n",
    "               \"tanks\", \"trees\", \"water\"]\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_bar = tqdm(val_loader, desc=\"Validation: \")\n",
    "        for batch in tqdm_bar:\n",
    "\n",
    "            images = batch[\"img\"].to(device) #Array of images\n",
    "            labels = batch[\"label\"].to(device) #Array of labels\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            logits = model(images)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            loss_tracker.update(loss.item(), batch_size)\n",
    "            predicted_prob, predicted_labels = torch.topk(probs.data, 17)\n",
    "            #predicted_prob, predicted_labels = torch.max(probs.data, 1)\n",
    "            \n",
    "            \n",
    "           # batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "            #acc_tracker.update(batch_acc, batch_size)\n",
    "            acc_tracker.update(batch_size)\n",
    "\n",
    "            y_pred += predicted_labels.tolist()\n",
    "            y_true += labels.tolist()\n",
    "            \n",
    "            y_pred_arr = np.array(y_pred)\n",
    "            y_true_arr = np.array(y_true)\n",
    "           \n",
    "        \n",
    "        return images, labels, y_pred_arr, y_true_arr, logits, probs, predicted_labels\n",
    "          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "60658d9b-5726-489a-ae80-d9beb439b73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T18:52:56.170676Z",
     "iopub.status.busy": "2022-07-15T18:52:56.170266Z",
     "iopub.status.idle": "2022-07-15T18:52:56.826051Z",
     "shell.execute_reply": "2022-07-15T18:52:56.824833Z",
     "shell.execute_reply.started": "2022-07-15T18:52:56.170651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccaf7ca0025405380a392865e7bf215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y true values are:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "(210, 17)\n",
      "Y prediction values are:  [[ 8  4 10 ...  5 15  1]\n",
      " [ 5  6  0 ...  7 16  1]\n",
      " [14 13 12 ... 16  4  9]\n",
      " ...\n",
      " [13  8 14 ... 16  1 15]\n",
      " [ 0  8 12 ...  1  4 16]\n",
      " [13  6  8 ...  2  4 15]]\n",
      "(210, 17)\n",
      "Type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Idea taken from the following website: https://colab.research.google.com/github/kmkarakaya/ML_tutorials/blob/master/Multi_Label_Model_Evaulation.ipynb#scrollTo=H8WBPN1OxXmw\n",
    "# We have 210 values because our validation takes 10% of our data so we get 210 values out of 2100\n",
    "im, lb, y_prediction, y_true, log, probs, pre = val_epoch(model, val_loader, criterion, cuda_device)\n",
    "print(\"Y true values are: \", y_true)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(\"Y prediction values are: \", y_prediction)\n",
    "print(y_prediction.shape)\n",
    "print(\"Type: \", type(y_prediction))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "18ab0785-e808-41e3-b600-ac6994cb7bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T19:20:15.149410Z",
     "iopub.status.busy": "2022-07-15T19:20:15.149003Z",
     "iopub.status.idle": "2022-07-15T19:20:15.172971Z",
     "shell.execute_reply": "2022-07-15T19:20:15.172097Z",
     "shell.execute_reply.started": "2022-07-15T19:20:15.149381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3125 0.375  0.     ... 0.4375 1.     0.0625]\n",
      " [0.3125 0.375  0.     ... 0.4375 1.     0.0625]\n",
      " [0.5    0.3125 0.75   ... 0.125  0.9375 0.0625]\n",
      " ...\n",
      " [0.3125 0.375  0.625  ... 0.0625 1.     0.4375]\n",
      " [0.8125 0.5    0.375  ... 0.5625 0.9375 1.    ]\n",
      " [0.3125 0.375  0.625  ... 0.0625 1.     0.4375]]\n",
      "(210, 17)\n"
     ]
    }
   ],
   "source": [
    "# We can normalize the y_prediction values between 0 & 1\n",
    "\n",
    "\n",
    "\n",
    "def normalization(arr: np.array) -> np.array:\n",
    "    norm = []\n",
    "    min_val = np.amin(arr)\n",
    "    max_val = np.amax(arr)\n",
    "    \n",
    "    for i in arr:\n",
    "        for j in i:\n",
    "            z = ((arr[j] - min_val)/ (max_val -min_val))\n",
    "        norm.append(z)\n",
    "\n",
    "    norm = np.array(norm)\n",
    "    \n",
    "    return norm\n",
    "\n",
    "\n",
    "y_prediction_normalize  = normalization(y_prediction)\n",
    "print(y_prediction_normalize)\n",
    "print(y_prediction_normalize.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b9a63bd-d47d-4518-919b-e86222335f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T18:46:44.741696Z",
     "iopub.status.busy": "2022-07-15T18:46:44.741293Z",
     "iopub.status.idle": "2022-07-15T18:46:44.749379Z",
     "shell.execute_reply": "2022-07-15T18:46:44.748237Z",
     "shell.execute_reply.started": "2022-07-15T18:46:44.741668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(210, 17)\n"
     ]
    }
   ],
   "source": [
    "# Now we perform segmentation. Values > 0.5 -> 1 while other -> 0\n",
    "\n",
    "\n",
    "y_pred_segmented=[]\n",
    "\n",
    "y_pred_segmented = np.where(y_prediction_normalize > 0.5, 1, 0) \n",
    "\n",
    "y_pred_segmented = np.array(y_pred_segmented)\n",
    "print(y_pred_segmented)\n",
    "print(y_pred_segmented.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4c0846d-2012-4902-8da4-b6738bca4417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T18:11:46.672451Z",
     "iopub.status.busy": "2022-07-15T18:11:46.672110Z",
     "iopub.status.idle": "2022-07-15T18:11:46.693763Z",
     "shell.execute_reply": "2022-07-15T18:11:46.692747Z",
     "shell.execute_reply.started": "2022-07-15T18:11:46.672424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.03      0.25      0.05         4\n",
      "   bare-soil       0.71      0.08      0.14        63\n",
      "   buildings       0.32      0.93      0.47        67\n",
      "        cars       0.47      0.55      0.51        89\n",
      "   chaparral       0.03      0.50      0.05         6\n",
      "       court       0.06      0.64      0.10        11\n",
      "        dock       0.04      0.64      0.07        11\n",
      "       field       0.02      0.17      0.04        12\n",
      "       grass       0.44      0.75      0.56        93\n",
      " mobile-home       0.09      0.50      0.16        14\n",
      "    pavement       0.53      0.42      0.47       133\n",
      "        sand       0.04      0.03      0.03        34\n",
      "         sea       0.05      0.70      0.10        10\n",
      "        ship       0.04      0.55      0.08        11\n",
      "       tanks       0.04      0.50      0.08         6\n",
      "       trees       0.51      0.49      0.50       112\n",
      "       water       0.08      0.04      0.06        24\n",
      "\n",
      "   micro avg       0.20      0.49      0.29       700\n",
      "   macro avg       0.21      0.45      0.20       700\n",
      "weighted avg       0.41      0.49      0.38       700\n",
      " samples avg       0.20      0.43      0.27       700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix:\n",
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, average_precision_score\n",
    "st = multilabel_confusion_matrix(y_true, y_pred_segmented)\n",
    "\n",
    "\n",
    "classLabels = [\"airplane\", \"bare-soil\", \"buildings\", \"cars\",\"chaparral\", \"court\", \"dock\", \"field\", \"grass\", \"mobile-home\",\"pavement\",\"sand\", \"sea\",\"ship\",\n",
    "               \"tanks\", \"trees\", \"water\"]\n",
    "\n",
    "#Classifcation report\n",
    "#Check the following link to understand all the column: https://medium.com/synthesio-engineering/precision-accuracy-and-f1-score-for-multi-label-classification-34ac6bdfb404\n",
    "M = classification_report(y_true, y_pred_segmented,target_names=classLabels)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4eb26fe-e226-4f2c-aa0f-09ad23352bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T18:08:57.249161Z",
     "iopub.status.busy": "2022-07-15T18:08:57.248725Z",
     "iopub.status.idle": "2022-07-15T18:08:57.337152Z",
     "shell.execute_reply": "2022-07-15T18:08:57.335049Z",
     "shell.execute_reply.started": "2022-07-15T18:08:57.249121Z"
    }
   },
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'maximum' did not contain a loop with signature matching types (dtype('<U21'), dtype('<U21')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#f1-score micro\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_segmented\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassLabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1132\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[1;32m    998\u001b[0m     y_true,\n\u001b[1;32m    999\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1006\u001b[0m ):\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \n\u001b[1;32m   1009\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1270\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[1;32m   1145\u001b[0m     y_true,\n\u001b[1;32m   1146\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1154\u001b[0m ):\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1560\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1560\u001b[0m MCM \u001b[38;5;241m=\u001b[39m \u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplewise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamplewise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1567\u001b[0m tp_sum \u001b[38;5;241m=\u001b[39m MCM[:, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1568\u001b[0m pred_sum \u001b[38;5;241m=\u001b[39m tp_sum \u001b[38;5;241m+\u001b[39m MCM[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:542\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# All labels are index integers for multilabel.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Select labels:\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(labels, present_labels):\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(present_labels):\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    544\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll labels must be in [0, n labels) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel targets. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m > \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (np\u001b[38;5;241m.\u001b[39mmax(labels), np\u001b[38;5;241m.\u001b[39mmax(present_labels))\n\u001b[1;32m    547\u001b[0m         )\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(labels) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2793\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2679\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2680\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2791\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2792\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2794\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'maximum' did not contain a loop with signature matching types (dtype('<U21'), dtype('<U21')) -> None"
     ]
    }
   ],
   "source": [
    "#f1-score micro\n",
    "\n",
    "f1_score(y_true, y_pred_segmented, labels=classLabels, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e409d3ba-14b5-424b-9635-ef1231e8ab80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T17:13:30.070873Z",
     "iopub.status.busy": "2022-07-15T17:13:30.070521Z",
     "iopub.status.idle": "2022-07-15T17:13:31.744479Z",
     "shell.execute_reply": "2022-07-15T17:13:31.742830Z",
     "shell.execute_reply.started": "2022-07-15T17:13:30.070845Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(17, 2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprettify_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclassLabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36mprettify_confusion_matrix\u001b[0;34m(conf_mat, class_names)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprettify_confusion_matrix\u001b[39m(conf_mat, class_names):\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m     \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf_mat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mviridis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mannot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/seaborn/_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass the following variable\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mkeyword arg\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/seaborn/matrix.py:540\u001b[0m, in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;124;03m    ...     ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True)\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[1;32m    545\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/seaborn/matrix.py:106\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[0;32m--> 106\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Validate the mask and convet to DataFrame\u001b[39;00m\n\u001b[1;32m    109\u001b[0m mask \u001b[38;5;241m=\u001b[39m _matrix_mask(data, mask)\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/pandas/core/frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    692\u001b[0m         )\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/pandas/core/internals/construction.py:331\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    326\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_prep_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dtype_equal(values\u001b[38;5;241m.\u001b[39mdtype, dtype):\n\u001b[1;32m    334\u001b[0m     shape \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/pandas/core/internals/construction.py:591\u001b[0m, in \u001b[0;36m_prep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    589\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(17, 2, 2)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdb3c2-acc9-47ac-a295-e590848da635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a2b36-f078-46b7-8ed5-246f3a8677cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e5b30-a747-4599-97f2-0a18cc13be33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b4ebd-8f48-4d3d-a193-4e4c4f296663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851df786-d2c2-4756-a1f5-c7bf830d089f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d242938-fd6b-470a-a271-b4d631c42a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f4cfb-03c9-4420-ba69-4da9ea643312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929061bd-9125-4bf0-91df-1c096a333e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa0d4d-fc41-45f1-a3cc-ea835fd2f282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b05ad8-a6b8-4f3e-a553-bc850daf5156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171a4ef-ade1-4c2b-b9af-708655bde7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb60e36-f55b-4645-82c4-bd77bdbb95e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bf598-3d58-4ec9-9779-be34b2804d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f775b0-5f6d-4442-9d27-b77c8ab89d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0489f1-9fe1-481b-a517-7f4fce4e7b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac7fb6-a7ac-4863-ad8d-fff6c9febca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0773d-1d0d-4127-bc79-526dbbb87b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff31dda-829d-46a4-afd7-dd66d353ab41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip4rs",
   "language": "python",
   "name": "ip4rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

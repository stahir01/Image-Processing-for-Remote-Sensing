{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e94269a-5bca-4a57-8c42-5f7439f4773a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:28.007962Z",
     "iopub.status.busy": "2022-07-14T12:40:28.007432Z",
     "iopub.status.idle": "2022-07-14T12:40:28.016471Z",
     "shell.execute_reply": "2022-07-14T12:40:28.014099Z",
     "shell.execute_reply.started": "2022-07-14T12:40:28.007923Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from simple_downloader import download\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4a6bed-5835-4132-b310-a77f67f2793c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:28.020425Z",
     "iopub.status.busy": "2022-07-14T12:40:28.020176Z",
     "iopub.status.idle": "2022-07-14T12:40:28.030908Z",
     "shell.execute_reply": "2022-07-14T12:40:28.029745Z",
     "shell.execute_reply.started": "2022-07-14T12:40:28.020400Z"
    }
   },
   "outputs": [],
   "source": [
    "class UCMerced(Dataset):\n",
    "    def __init__(self, root_dir, img_transform=None, multilabel=True):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.images_path = os.path.join(root_dir, \"Images\")\n",
    "        self.class_names = sorted(\n",
    "            [cl for cl in os.listdir(self.images_path) if not cl.startswith(\".\")]\n",
    "        )\n",
    "        self.img_paths, self.img_labels = self.init_dataset()\n",
    "        self.img_transform = img_transform\n",
    "\n",
    "        if multilabel:\n",
    "            self.img_labels = self.read_multilabels()  # important for loss calculation\n",
    "            self.img_labels = self.img_labels.astype(float)\n",
    "\n",
    "    def init_dataset(self):\n",
    "        img_paths, img_labels = [], []\n",
    "        for cl_id, cl_name in enumerate(self.class_names):\n",
    "            cl_path = os.path.join(self.images_path, cl_name)\n",
    "\n",
    "            for img in sorted(os.listdir(cl_path)):\n",
    "                img_path = os.path.join(cl_path, img)\n",
    "                img_paths.append(img_path)\n",
    "                img_labels.append(cl_id)\n",
    "\n",
    "        return img_paths, img_labels\n",
    "\n",
    "    def read_multilabels(self):\n",
    "        label = pd.read_excel(\"./Hw3_data/UCMerced_LandUse/multilabels/LandUse_Multilabeled.xlsx\")\n",
    "        label = label.set_index(\"IMAGE\\LABEL\")\n",
    "        label = np.array(label)\n",
    "        return label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(img)\n",
    "\n",
    "        return dict(img=img, label=label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeff5703-931e-45ca-b2a0-7e36913630dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:29.114516Z",
     "iopub.status.busy": "2022-07-14T12:40:29.113699Z",
     "iopub.status.idle": "2022-07-14T12:40:29.121805Z",
     "shell.execute_reply": "2022-07-14T12:40:29.120340Z",
     "shell.execute_reply.started": "2022-07-14T12:40:29.114485Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetricTracker(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af72c425-858b-4ac9-a29b-b134e9c8c97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:29.703998Z",
     "iopub.status.busy": "2022-07-14T12:40:29.703240Z",
     "iopub.status.idle": "2022-07-14T12:40:29.710037Z",
     "shell.execute_reply": "2022-07-14T12:40:29.708623Z",
     "shell.execute_reply.started": "2022-07-14T12:40:29.703971Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_device(cuda_int):\n",
    "    \"\"\"Get Cuda-Device. If cuda_int < 0 compute on CPU.\"\"\"\n",
    "    if cuda_int < 0:\n",
    "        print(\"Computation on CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"Computation on CUDA GPU device {}\".format(cuda_int))\n",
    "        device = torch.device(\"cuda:{}\".format(cuda_int))\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba7d50f-1d3e-4f4e-9a27-7adda55aa865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:30.197091Z",
     "iopub.status.busy": "2022-07-14T12:40:30.196158Z",
     "iopub.status.idle": "2022-07-14T12:40:30.203210Z",
     "shell.execute_reply": "2022-07-14T12:40:30.202424Z",
     "shell.execute_reply.started": "2022-07-14T12:40:30.197062Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets ,models , transforms\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader ,random_split\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.optim import Adam\n",
    "\n",
    "def get_dataset(root_dir, tr_transform,seed=1, multilabel=True):\n",
    "    valid_no = int(2100*0.1)\n",
    "    train_no = int(2100*0.7) \n",
    "    test_no = int(2100*0.2)\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ---------\n",
    "    root_dir     : path to UCMerced Dataset\n",
    "    tr_transform : transformation for training data\n",
    "    te_transform : transformation for training data\n",
    "    set_sizes    : list of percentage of either train-test or train-val-test (sum to 100)\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    sets for train and test, optionally also val if len(set_sizes)==3\n",
    "    \"\"\"\n",
    "    ucm_dataset_tr = UCMerced(root_dir, img_transform=tr_transform, multilabel=multilabel)\n",
    "    #ucm_dataset_te = UCMerced(root_dir, img_transform=te_transform, multilabel=multilabel)\n",
    "    \n",
    "    trainset ,validset, testset  = random_split(ucm_dataset_tr, [train_no, valid_no, test_no])\n",
    "    \n",
    "    return trainset ,validset, testset\n",
    "    \n",
    "    \n",
    "    #idx_list = split_ucm_indices(set_sizes, seed=seed)\n",
    "\n",
    "   # train_set = Subset(ucm_dataset_tr, idx_list[0])\n",
    "    #test_set = Subset(ucm_dataset_te, idx_list[-1])\n",
    "\n",
    "    #if len(idx_list) > 2:\n",
    "     #   val_set = Subset(ucm_dataset_te, idx_list[1])\n",
    "      #  return train_set, val_set, test_set\n",
    "    #else:\n",
    "     #   return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e27cd-697e-494a-b93f-0f3ec05aaec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06bcca3a-c413-46fc-ba33-bd03930c0e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:32.034712Z",
     "iopub.status.busy": "2022-07-14T12:40:32.033876Z",
     "iopub.status.idle": "2022-07-14T12:40:32.039961Z",
     "shell.execute_reply": "2022-07-14T12:40:32.038619Z",
     "shell.execute_reply.started": "2022-07-14T12:40:32.034681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation on CPU\n"
     ]
    }
   ],
   "source": [
    "cuda_device = get_device(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f2f9ad-276e-4d8c-a4a3-8f9a2d0809cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:32.436940Z",
     "iopub.status.busy": "2022-07-14T12:40:32.436588Z",
     "iopub.status.idle": "2022-07-14T12:40:32.441142Z",
     "shell.execute_reply": "2022-07-14T12:40:32.440362Z",
     "shell.execute_reply.started": "2022-07-14T12:40:32.436914Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "num_cls = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b104c9d-3e74-474d-ac16-f74251462c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:33.753582Z",
     "iopub.status.busy": "2022-07-14T12:40:33.753208Z",
     "iopub.status.idle": "2022-07-14T12:40:33.760579Z",
     "shell.execute_reply": "2022-07-14T12:40:33.759484Z",
     "shell.execute_reply.started": "2022-07-14T12:40:33.753556Z"
    }
   },
   "outputs": [],
   "source": [
    "ucm_mean = [0.595425, 0.3518577, 0.3225522]\n",
    "ucm_std = [0.19303136, 0.12492529, 0.10577361]\n",
    "\n",
    "#So we resize the images so all image have same size\n",
    "#This is how we transform all images\n",
    "\n",
    "#We do it for both training and testing data\n",
    "#For further understanding, pls refer to the following webste: https://www.programcreek.com/python/example/104832/torchvision.transforms.Compose\n",
    "\n",
    "tr_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=ucm_mean, std=ucm_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "te_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=ucm_mean, std=ucm_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0bb8c9-dee6-4579-9459-023ac17f47e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:34.353868Z",
     "iopub.status.busy": "2022-07-14T12:40:34.353523Z",
     "iopub.status.idle": "2022-07-14T12:40:35.417747Z",
     "shell.execute_reply": "2022-07-14T12:40:35.416843Z",
     "shell.execute_reply.started": "2022-07-14T12:40:34.353842Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset, valset, testset = get_dataset(\n",
    "    \"./Hw3_data/UCMerced_LandUse\",\n",
    "    tr_transform=tr_transform,\n",
    "    multilabel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b6638c1-aa85-4824-b54e-8ce639983b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:35.419402Z",
     "iopub.status.busy": "2022-07-14T12:40:35.419154Z",
     "iopub.status.idle": "2022-07-14T12:40:35.425429Z",
     "shell.execute_reply": "2022-07-14T12:40:35.423701Z",
     "shell.execute_reply.started": "2022-07-14T12:40:35.419378Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea52a99-0770-43f6-b608-906da0b58ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:36.236350Z",
     "iopub.status.busy": "2022-07-14T12:40:36.235378Z",
     "iopub.status.idle": "2022-07-14T12:40:38.550207Z",
     "shell.execute_reply": "2022-07-14T12:40:38.549095Z",
     "shell.execute_reply.started": "2022-07-14T12:40:36.236294Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fa75724c8a415d88665fada569940f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(512, 17) #21 - number of classes\n",
    "model.to(cuda_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54eb38b1-ee40-40b2-afc7-2aeaf4e8be0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:38.556534Z",
     "iopub.status.busy": "2022-07-14T12:40:38.556177Z",
     "iopub.status.idle": "2022-07-14T12:40:38.563357Z",
     "shell.execute_reply": "2022-07-14T12:40:38.562139Z",
     "shell.execute_reply.started": "2022-07-14T12:40:38.556499Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.BCEWithLogitsLoss().to(cuda_device)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "sgdr_partial = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0.005 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d3a7b2-bf97-4df9-ac84-be19841ff20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:38.568270Z",
     "iopub.status.busy": "2022-07-14T12:40:38.568035Z",
     "iopub.status.idle": "2022-07-14T12:40:38.574804Z",
     "shell.execute_reply": "2022-07-14T12:40:38.573813Z",
     "shell.execute_reply.started": "2022-07-14T12:40:38.568247Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, epochs, device, early_stop=False):\n",
    "    train_losses, val_losses = [], []\n",
    "    accuracy_scores = []\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_acc = 0\n",
    "    best_epoch = 1\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        print(\"Epoch {}/{}\".format(epoch, epochs))\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, report, _ = val_epoch(model, val_loader, criterion, device)\n",
    "        overall_acc = report[\"accuracy\"]\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        accuracy_scores.append(overall_acc)\n",
    "\n",
    "        if best_acc < overall_acc:\n",
    "            best_acc = overall_acc\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "        if epoch - best_epoch > 10 and early_stop:\n",
    "            break\n",
    "\n",
    "    return best_model, train_losses, val_losses, accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "472ff0aa-cc35-41f4-8584-a94042d12026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:39.233406Z",
     "iopub.status.busy": "2022-07-14T12:40:39.233054Z",
     "iopub.status.idle": "2022-07-14T12:40:39.240729Z",
     "shell.execute_reply": "2022-07-14T12:40:39.239638Z",
     "shell.execute_reply.started": "2022-07-14T12:40:39.233380Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.train()\n",
    "\n",
    "    tqdm_bar = tqdm(train_loader, desc=\"Training: \")\n",
    "    for batch in tqdm_bar:\n",
    "\n",
    "        images = batch[\"img\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        batch_size = images.size(0)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        #loss = criterion(logits, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        loss_tracker.update(loss.item(), batch_size)\n",
    "\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        #batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "        #acc_tracker.update(batch_acc, batch_size)\n",
    "        tqdm_bar.set_postfix(loss=loss_tracker.avg, accuracy=acc_tracker.avg)\n",
    "        tqdm_bar.set_postfix(loss=loss_tracker.avg)\n",
    "\n",
    "    return loss_tracker.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f3903f7-15aa-4e4a-9d2d-f8a9477debdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:39.533267Z",
     "iopub.status.busy": "2022-07-14T12:40:39.532273Z",
     "iopub.status.idle": "2022-07-14T12:40:39.542195Z",
     "shell.execute_reply": "2022-07-14T12:40:39.540505Z",
     "shell.execute_reply.started": "2022-07-14T12:40:39.533230Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_bar = tqdm(val_loader, desc=\"Validation: \")\n",
    "        for batch in tqdm_bar:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            logits = model(images)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss_tracker.update(loss.item(), batch_size)\n",
    "\n",
    "            _, predicted = torch.max(probs.data, 1)\n",
    "           # batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "            #acc_tracker.update(batch_acc, batch_size)\n",
    "            acc_tracker.update(batch_size)\n",
    "\n",
    "            y_pred += predicted.tolist()\n",
    "            y_true += labels.tolist()\n",
    "            tqdm_bar.set_postfix(loss=loss_tracker.avg, accuracy=acc_tracker.avg)\n",
    "            \n",
    "\n",
    "    report = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    conf_mat = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "        \n",
    "    return loss_tracker.avg, report, conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e9570c1-5452-4638-bead-b77061f6d648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:40.765398Z",
     "iopub.status.busy": "2022-07-14T12:40:40.765023Z",
     "iopub.status.idle": "2022-07-14T12:40:40.769171Z",
     "shell.execute_reply": "2022-07-14T12:40:40.768400Z",
     "shell.execute_reply.started": "2022-07-14T12:40:40.765371Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e17a9ee0-48c6-43df-9f7c-391be9c4325c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T12:40:41.960390Z",
     "iopub.status.busy": "2022-07-14T12:40:41.960040Z",
     "iopub.status.idle": "2022-07-14T12:41:12.291210Z",
     "shell.execute_reply": "2022-07-14T12:41:12.288447Z",
     "shell.execute_reply.started": "2022-07-14T12:40:41.960364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304f5ab16c5a43a5b43909602d64bcb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b33badf418409caec0933f13de454d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model, train_losses, val_losses, accuracy_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m eval_accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy_scores)\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, epochs, device, early_stop)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     13\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[0;32m---> 14\u001b[0m val_loss, report, _ \u001b[38;5;241m=\u001b[39m \u001b[43mval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m overall_acc \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mval_epoch\u001b[0;34m(model, val_loader, criterion, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m         y_true \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     29\u001b[0m         tqdm_bar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss_tracker\u001b[38;5;241m.\u001b[39mavg, accuracy\u001b[38;5;241m=\u001b[39macc_tracker\u001b[38;5;241m.\u001b[39mavg)\n\u001b[0;32m---> 32\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m conf_mat \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_tracker\u001b[38;5;241m.\u001b[39mavg, report, conf_mat\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2125\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[1;32m   2011\u001b[0m     y_true,\n\u001b[1;32m   2012\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2020\u001b[0m ):\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \n\u001b[1;32m   2023\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2125\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2128\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "best_model, train_losses, val_losses, accuracy_scores = train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    epochs=3,\n",
    "    device=cuda_device,\n",
    ")\n",
    "eval_accuracies.append(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fae4c3b-fa64-4335-a8a6-ee99f5c688ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T13:06:30.734799Z",
     "iopub.status.busy": "2022-07-14T13:06:30.734096Z",
     "iopub.status.idle": "2022-07-14T13:06:30.742132Z",
     "shell.execute_reply": "2022-07-14T13:06:30.741293Z",
     "shell.execute_reply.started": "2022-07-14T13:06:30.734763Z"
    }
   },
   "outputs": [],
   "source": [
    "#Testing val_epoch to test results\n",
    "\n",
    "\n",
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_bar = tqdm(val_loader, desc=\"Validation: \")\n",
    "        for batch in tqdm_bar:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            logits = model(images)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss_tracker.update(loss.item(), batch_size)\n",
    "\n",
    "            _, predicted = torch.max(probs.data, 1)\n",
    "           # batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "            #acc_tracker.update(batch_acc, batch_size)\n",
    "            acc_tracker.update(batch_size)\n",
    "\n",
    "            y_pred += predicted.tolist()\n",
    "            y_true += labels.tolist()\n",
    "            \n",
    "            y_pred_arr = np.array(y_pred)\n",
    "            y_true_arr = np.array(y_true)\n",
    "            \n",
    "        \n",
    "        return y_pred_arr, y_true_arr\n",
    "          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60658d9b-5726-489a-ae80-d9beb439b73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T13:49:59.644797Z",
     "iopub.status.busy": "2022-07-14T13:49:59.644459Z",
     "iopub.status.idle": "2022-07-14T13:50:00.584338Z",
     "shell.execute_reply": "2022-07-14T13:50:00.583234Z",
     "shell.execute_reply.started": "2022-07-14T13:49:59.644771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5d2e5f5bf843a0b85d376a52321db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y true values are:  [[0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 1. 0.]]\n",
      "Y prediction values are:  [ 8  8 10  7  7  9 10  0  2 15  4 10  6 10 10 10 13 15 10  1  2  8  8 10\n",
      " 10 10  8  8  8  8 10 10 10  8 10 10 10 13 10 10  1 10  8  8 10 10 15 10\n",
      " 10 15 10 12  8  7 10 12  1 10  1 10 10  8 14  7  8 15 10 10 10 13 10 10\n",
      "  7  1 10  8 10 10 10 12 10  4  7 10  8  8  8  6 10  0  1  0 13 10 10 14\n",
      " 10 12  7  8 10 15  1 10 10 10  8  1 10 14 10 10  0  0  8  2 10 15  6  8\n",
      "  1  7  8  1 15 10  8 11 10  8 13 15 12  7 11 10 10  7  8  0  8 10  7 10\n",
      " 15 10  6 10  0 10 10 11 10 10  7  8  8  0 10  8 10 10  2 10  7  2 12 10\n",
      "  4  8 10  8  8  1 14 12  4 10 10 10  0 10 10 10  8 10 10  8  7 10 10  8\n",
      " 10  6 10  8  0  8  8  8 10 10  2  9 15  7 10 10  8  8]\n",
      "(210, 17)\n",
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "#Idea taken from the following website: https://colab.research.google.com/github/kmkarakaya/ML_tutorials/blob/master/Multi_Label_Model_Evaulation.ipynb#scrollTo=H8WBPN1OxXmw\n",
    "# We have 210 values because our validation takes 10% of our data so we get 210 values out of 2100\n",
    "y_prediction, y_true = val_epoch(model, val_loader, criterion, cuda_device)\n",
    "print(\"Y true values are: \", y_true)\n",
    "print(\"Y prediction values are: \", y_prediction)\n",
    "print(y_true.shape)\n",
    "print(y_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "559d6b67-ab1f-4b50-b9ad-feeb784b23e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T13:59:30.351805Z",
     "iopub.status.busy": "2022-07-14T13:59:30.350812Z",
     "iopub.status.idle": "2022-07-14T13:59:30.361084Z",
     "shell.execute_reply": "2022-07-14T13:59:30.360253Z",
     "shell.execute_reply.started": "2022-07-14T13:59:30.351767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.4666666666666667,\n",
       " 0.4666666666666667,\n",
       " 0.6,\n",
       " 0.6666666666666666,\n",
       " 0.0,\n",
       " 0.13333333333333333,\n",
       " 1.0,\n",
       " 0.26666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.4,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.8666666666666667,\n",
       " 1.0,\n",
       " 0.6666666666666666,\n",
       " 0.06666666666666667,\n",
       " 0.13333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.8666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.06666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 1.0,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 1.0,\n",
       " 0.6666666666666666,\n",
       " 0.8,\n",
       " 0.5333333333333333,\n",
       " 0.4666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.8,\n",
       " 0.06666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.06666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.4666666666666667,\n",
       " 0.5333333333333333,\n",
       " 1.0,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.8666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.4666666666666667,\n",
       " 0.06666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.8,\n",
       " 0.6666666666666666,\n",
       " 0.26666666666666666,\n",
       " 0.4666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.4,\n",
       " 0.6666666666666666,\n",
       " 0.0,\n",
       " 0.06666666666666667,\n",
       " 0.0,\n",
       " 0.8666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.9333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.8,\n",
       " 0.4666666666666667,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 1.0,\n",
       " 0.06666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.06666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.9333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5333333333333333,\n",
       " 0.13333333333333333,\n",
       " 0.6666666666666666,\n",
       " 1.0,\n",
       " 0.4,\n",
       " 0.5333333333333333,\n",
       " 0.06666666666666667,\n",
       " 0.4666666666666667,\n",
       " 0.5333333333333333,\n",
       " 0.06666666666666667,\n",
       " 1.0,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.7333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.8666666666666667,\n",
       " 1.0,\n",
       " 0.8,\n",
       " 0.4666666666666667,\n",
       " 0.7333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.4666666666666667,\n",
       " 0.5333333333333333,\n",
       " 0.0,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.4666666666666667,\n",
       " 0.6666666666666666,\n",
       " 1.0,\n",
       " 0.6666666666666666,\n",
       " 0.4,\n",
       " 0.6666666666666666,\n",
       " 0.0,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.7333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.4666666666666667,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.0,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.13333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.4666666666666667,\n",
       " 0.13333333333333333,\n",
       " 0.8,\n",
       " 0.6666666666666666,\n",
       " 0.26666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.06666666666666667,\n",
       " 0.9333333333333333,\n",
       " 0.8,\n",
       " 0.26666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.0,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.4666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.4,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.0,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.13333333333333333,\n",
       " 0.6,\n",
       " 1.0,\n",
       " 0.4666666666666667,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can normalize the y_prediction values between 0 & 1\n",
    "y_prediction_normalize = []\n",
    "min_val = min(y_prediction)\n",
    "max_val = max(y_prediction)\n",
    "for i in range(len(y_prediction)):\n",
    "    z = ((y_prediction[i] - min_val)/ (max_val -min_val))\n",
    "    y_prediction_normalize.append(z)\n",
    "    \n",
    "y_prediction_normalize\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7104c54-3ad8-4be8-9313-6df69ab9604f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:02:19.540610Z",
     "iopub.status.busy": "2022-07-14T14:02:19.540141Z",
     "iopub.status.idle": "2022-07-14T14:02:19.553285Z",
     "shell.execute_reply": "2022-07-14T14:02:19.552009Z",
     "shell.execute_reply.started": "2022-07-14T14:02:19.540572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold: Let's assume we are using 0.5 as the threshold for prediction\n",
    "\n",
    "y_pred_final=[]\n",
    "for sample in  y_prediction_normalize:\n",
    "    if sample > 0.5:\n",
    "        y_pred_final.append(1)\n",
    "    else:\n",
    "        y_pred_final.append(0)\n",
    "        \n",
    "y_pred_final = np.array(y_pred_final)\n",
    "y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "616fb95c-9f4e-454e-a684-1baa44cccd15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:05:05.995964Z",
     "iopub.status.busy": "2022-07-14T14:05:05.995369Z",
     "iopub.status.idle": "2022-07-14T14:05:06.042417Z",
     "shell.execute_reply": "2022-07-14T14:05:06.041207Z",
     "shell.execute_reply.started": "2022-07-14T14:05:05.995937Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multilabel_confusion_matrix\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_final\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:479\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmultilabel_confusion_matrix\u001b[39m(\n\u001b[1;32m    380\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplewise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    381\u001b[0m ):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m            [1, 2]]])\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m column_or_1d(sample_weight)\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_true, y_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3af4024a-4d28-4e02-8b02-0429c9f4291b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:56:08.172328Z",
     "iopub.status.busy": "2022-07-14T14:56:08.171391Z",
     "iopub.status.idle": "2022-07-14T14:56:08.176625Z",
     "shell.execute_reply": "2022-07-14T14:56:08.175779Z",
     "shell.execute_reply.started": "2022-07-14T14:56:08.172300Z"
    }
   },
   "outputs": [],
   "source": [
    "def prettify_confusion_matrix(conf_mat, class_names):\n",
    "    plt.subplots(1, 1, figsize=(11, 7))\n",
    "    sns.heatmap(\n",
    "        conf_mat,\n",
    "        cmap=\"viridis\",\n",
    "        fmt=\"g\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        annot=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a67fc-0168-4854-9216-729e30bdb076",
   "metadata": {},
   "source": [
    "## Has to be deleted later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0182cfa4-5293-487e-aed3-c6b3b9eaa48d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:57:38.532121Z",
     "iopub.status.busy": "2022-07-14T14:57:38.531142Z",
     "iopub.status.idle": "2022-07-14T14:57:38.536430Z",
     "shell.execute_reply": "2022-07-14T14:57:38.535664Z",
     "shell.execute_reply.started": "2022-07-14T14:57:38.532092Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_t = np.array([[0, 1, 1, 1],[0,0,1,0],[1,1,0,0]])\n",
    "y_p = np.array([[0, 1, 0, 1],\n",
    "       [0, 1, 1, 1],\n",
    "       [1, 0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "379ec2bd-e1b6-4fbb-9f14-c78c8f5bf61c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:59:08.082543Z",
     "iopub.status.busy": "2022-07-14T14:59:08.081763Z",
     "iopub.status.idle": "2022-07-14T14:59:08.088554Z",
     "shell.execute_reply": "2022-07-14T14:59:08.087768Z",
     "shell.execute_reply.started": "2022-07-14T14:59:08.082515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2 0]\n",
      "  [0 1]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[0 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[0 2]\n",
      "  [0 1]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "st = multilabel_confusion_matrix(y_t, y_p)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92f5127e-64ca-4c6f-963f-c3baf99d9928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T15:03:17.121797Z",
     "iopub.status.busy": "2022-07-14T15:03:17.120703Z",
     "iopub.status.idle": "2022-07-14T15:03:17.137051Z",
     "shell.execute_reply": "2022-07-14T15:03:17.136259Z",
     "shell.execute_reply.started": "2022-07-14T15:03:17.121761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     label A       1.00      1.00      1.00         1\n",
      "     label B       0.50      0.50      0.50         2\n",
      "     label C       0.50      0.50      0.50         2\n",
      "     label D       0.33      1.00      0.50         1\n",
      "\n",
      "   micro avg       0.50      0.67      0.57         6\n",
      "   macro avg       0.58      0.75      0.62         6\n",
      "weighted avg       0.56      0.67      0.58         6\n",
      " samples avg       0.56      0.72      0.57         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = ['label A', 'label B', 'label C', 'label D']\n",
    "\n",
    "print(classification_report(y_t, y_p,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb7068-2ba6-44d1-904a-93f6202535a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11735e-0d01-4564-9bb4-2b786ee290f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdb3c2-acc9-47ac-a295-e590848da635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a2b36-f078-46b7-8ed5-246f3a8677cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e5b30-a747-4599-97f2-0a18cc13be33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b4ebd-8f48-4d3d-a193-4e4c4f296663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851df786-d2c2-4756-a1f5-c7bf830d089f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d242938-fd6b-470a-a271-b4d631c42a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f4cfb-03c9-4420-ba69-4da9ea643312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929061bd-9125-4bf0-91df-1c096a333e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa0d4d-fc41-45f1-a3cc-ea835fd2f282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b05ad8-a6b8-4f3e-a553-bc850daf5156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171a4ef-ade1-4c2b-b9af-708655bde7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb60e36-f55b-4645-82c4-bd77bdbb95e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bf598-3d58-4ec9-9779-be34b2804d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f775b0-5f6d-4442-9d27-b77c8ab89d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0489f1-9fe1-481b-a517-7f4fce4e7b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac7fb6-a7ac-4863-ad8d-fff6c9febca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0773d-1d0d-4127-bc79-526dbbb87b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff31dda-829d-46a4-afd7-dd66d353ab41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip4rs",
   "language": "python",
   "name": "ip4rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

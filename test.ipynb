{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e94269a-5bca-4a57-8c42-5f7439f4773a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:36.815938Z",
     "iopub.status.busy": "2022-07-14T18:44:36.815519Z",
     "iopub.status.idle": "2022-07-14T18:44:36.822031Z",
     "shell.execute_reply": "2022-07-14T18:44:36.820686Z",
     "shell.execute_reply.started": "2022-07-14T18:44:36.815911Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from simple_downloader import download\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4a6bed-5835-4132-b310-a77f67f2793c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:36.824379Z",
     "iopub.status.busy": "2022-07-14T18:44:36.823770Z",
     "iopub.status.idle": "2022-07-14T18:44:36.837733Z",
     "shell.execute_reply": "2022-07-14T18:44:36.836325Z",
     "shell.execute_reply.started": "2022-07-14T18:44:36.824338Z"
    }
   },
   "outputs": [],
   "source": [
    "class UCMerced(Dataset):\n",
    "    def __init__(self, root_dir, img_transform=None, multilabel=True):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.images_path = os.path.join(root_dir, \"Images\")\n",
    "        self.class_names = sorted(\n",
    "            [cl for cl in os.listdir(self.images_path) if not cl.startswith(\".\")]\n",
    "        )\n",
    "        self.img_paths, self.img_labels = self.init_dataset()\n",
    "        self.img_transform = img_transform\n",
    "\n",
    "        if multilabel:\n",
    "            self.img_labels = self.read_multilabels()  # important for loss calculation\n",
    "            self.img_labels = self.img_labels.astype(float)\n",
    "\n",
    "    def init_dataset(self):\n",
    "        img_paths, img_labels = [], []\n",
    "        for cl_id, cl_name in enumerate(self.class_names):\n",
    "            cl_path = os.path.join(self.images_path, cl_name)\n",
    "\n",
    "            for img in sorted(os.listdir(cl_path)):\n",
    "                img_path = os.path.join(cl_path, img)\n",
    "                img_paths.append(img_path)\n",
    "                img_labels.append(cl_id)\n",
    "\n",
    "        return img_paths, img_labels\n",
    "\n",
    "    def read_multilabels(self):\n",
    "        label = pd.read_excel(\"./Hw3_data/UCMerced_LandUse/multilabels/LandUse_Multilabeled.xlsx\")\n",
    "        label = label.set_index(\"IMAGE\\LABEL\")\n",
    "        label = np.array(label)\n",
    "        return label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(img)\n",
    "\n",
    "        return dict(img=img, label=label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeff5703-931e-45ca-b2a0-7e36913630dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:36.998590Z",
     "iopub.status.busy": "2022-07-14T18:44:36.998235Z",
     "iopub.status.idle": "2022-07-14T18:44:37.006192Z",
     "shell.execute_reply": "2022-07-14T18:44:37.004396Z",
     "shell.execute_reply.started": "2022-07-14T18:44:36.998561Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetricTracker(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af72c425-858b-4ac9-a29b-b134e9c8c97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:37.207751Z",
     "iopub.status.busy": "2022-07-14T18:44:37.207411Z",
     "iopub.status.idle": "2022-07-14T18:44:37.213060Z",
     "shell.execute_reply": "2022-07-14T18:44:37.212007Z",
     "shell.execute_reply.started": "2022-07-14T18:44:37.207725Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_device(cuda_int):\n",
    "    \"\"\"Get Cuda-Device. If cuda_int < 0 compute on CPU.\"\"\"\n",
    "    if cuda_int < 0:\n",
    "        print(\"Computation on CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"Computation on CUDA GPU device {}\".format(cuda_int))\n",
    "        device = torch.device(\"cuda:{}\".format(cuda_int))\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba7d50f-1d3e-4f4e-9a27-7adda55aa865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:37.362791Z",
     "iopub.status.busy": "2022-07-14T18:44:37.362451Z",
     "iopub.status.idle": "2022-07-14T18:44:37.370269Z",
     "shell.execute_reply": "2022-07-14T18:44:37.369233Z",
     "shell.execute_reply.started": "2022-07-14T18:44:37.362765Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets ,models , transforms\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader ,random_split\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.optim import Adam\n",
    "\n",
    "def get_dataset(root_dir, tr_transform,seed=1, multilabel=True):\n",
    "    valid_no = int(2100*0.1)\n",
    "    train_no = int(2100*0.7) \n",
    "    test_no = int(2100*0.2)\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ---------\n",
    "    root_dir     : path to UCMerced Dataset\n",
    "    tr_transform : transformation for training data\n",
    "    te_transform : transformation for training data\n",
    "    set_sizes    : list of percentage of either train-test or train-val-test (sum to 100)\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    sets for train and test, optionally also val if len(set_sizes)==3\n",
    "    \"\"\"\n",
    "    ucm_dataset_tr = UCMerced(root_dir, img_transform=tr_transform, multilabel=multilabel)\n",
    "    #ucm_dataset_te = UCMerced(root_dir, img_transform=te_transform, multilabel=multilabel)\n",
    "    \n",
    "    trainset ,validset, testset  = random_split(ucm_dataset_tr, [train_no, valid_no, test_no])\n",
    "    \n",
    "    return trainset ,validset, testset\n",
    "    \n",
    "    \n",
    "    #idx_list = split_ucm_indices(set_sizes, seed=seed)\n",
    "\n",
    "   # train_set = Subset(ucm_dataset_tr, idx_list[0])\n",
    "    #test_set = Subset(ucm_dataset_te, idx_list[-1])\n",
    "\n",
    "    #if len(idx_list) > 2:\n",
    "     #   val_set = Subset(ucm_dataset_te, idx_list[1])\n",
    "      #  return train_set, val_set, test_set\n",
    "    #else:\n",
    "     #   return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e27cd-697e-494a-b93f-0f3ec05aaec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06bcca3a-c413-46fc-ba33-bd03930c0e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:39.724334Z",
     "iopub.status.busy": "2022-07-14T18:44:39.723979Z",
     "iopub.status.idle": "2022-07-14T18:44:39.730962Z",
     "shell.execute_reply": "2022-07-14T18:44:39.729168Z",
     "shell.execute_reply.started": "2022-07-14T18:44:39.724307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation on CPU\n"
     ]
    }
   ],
   "source": [
    "cuda_device = get_device(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f2f9ad-276e-4d8c-a4a3-8f9a2d0809cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:39.943854Z",
     "iopub.status.busy": "2022-07-14T18:44:39.943447Z",
     "iopub.status.idle": "2022-07-14T18:44:39.948574Z",
     "shell.execute_reply": "2022-07-14T18:44:39.947451Z",
     "shell.execute_reply.started": "2022-07-14T18:44:39.943826Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "num_cls = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b104c9d-3e74-474d-ac16-f74251462c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:42.859524Z",
     "iopub.status.busy": "2022-07-14T18:44:42.858892Z",
     "iopub.status.idle": "2022-07-14T18:44:42.865775Z",
     "shell.execute_reply": "2022-07-14T18:44:42.864432Z",
     "shell.execute_reply.started": "2022-07-14T18:44:42.859497Z"
    }
   },
   "outputs": [],
   "source": [
    "ucm_mean = [0.595425, 0.3518577, 0.3225522]\n",
    "ucm_std = [0.19303136, 0.12492529, 0.10577361]\n",
    "\n",
    "#So we resize the images so all image have same size\n",
    "#This is how we transform all images\n",
    "\n",
    "#We do it for both training and testing data\n",
    "#For further understanding, pls refer to the following webste: https://www.programcreek.com/python/example/104832/torchvision.transforms.Compose\n",
    "\n",
    "tr_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=ucm_mean, std=ucm_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "te_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=ucm_mean, std=ucm_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0bb8c9-dee6-4579-9459-023ac17f47e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:43.316616Z",
     "iopub.status.busy": "2022-07-14T18:44:43.315890Z",
     "iopub.status.idle": "2022-07-14T18:44:44.231090Z",
     "shell.execute_reply": "2022-07-14T18:44:44.230296Z",
     "shell.execute_reply.started": "2022-07-14T18:44:43.316575Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset, valset, testset = get_dataset(\n",
    "    \"./Hw3_data/UCMerced_LandUse\",\n",
    "    tr_transform=tr_transform,\n",
    "    multilabel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b6638c1-aa85-4824-b54e-8ce639983b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:44.232724Z",
     "iopub.status.busy": "2022-07-14T18:44:44.232455Z",
     "iopub.status.idle": "2022-07-14T18:44:44.238128Z",
     "shell.execute_reply": "2022-07-14T18:44:44.236948Z",
     "shell.execute_reply.started": "2022-07-14T18:44:44.232673Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea52a99-0770-43f6-b608-906da0b58ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:44.240193Z",
     "iopub.status.busy": "2022-07-14T18:44:44.239777Z",
     "iopub.status.idle": "2022-07-14T18:44:46.737323Z",
     "shell.execute_reply": "2022-07-14T18:44:46.736147Z",
     "shell.execute_reply.started": "2022-07-14T18:44:44.240153Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b37bcdf14847309e3f597601cc6c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(512, 17) #21 - number of classes\n",
    "model.to(cuda_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54eb38b1-ee40-40b2-afc7-2aeaf4e8be0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:46.741066Z",
     "iopub.status.busy": "2022-07-14T18:44:46.740087Z",
     "iopub.status.idle": "2022-07-14T18:44:46.748061Z",
     "shell.execute_reply": "2022-07-14T18:44:46.747105Z",
     "shell.execute_reply.started": "2022-07-14T18:44:46.741026Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "#Criterion\n",
    "criterion = nn.BCEWithLogitsLoss().to(cuda_device)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d3a7b2-bf97-4df9-ac84-be19841ff20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:48.647770Z",
     "iopub.status.busy": "2022-07-14T18:44:48.647417Z",
     "iopub.status.idle": "2022-07-14T18:44:48.655456Z",
     "shell.execute_reply": "2022-07-14T18:44:48.654233Z",
     "shell.execute_reply.started": "2022-07-14T18:44:48.647738Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, epochs, device, early_stop=False):\n",
    "    train_losses, val_losses = [], []\n",
    "    accuracy_scores = []\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_acc = 0\n",
    "    best_epoch = 1\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        print(\"Epoch {}/{}\".format(epoch, epochs))\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, report, _ = val_epoch(model, val_loader, criterion, device)\n",
    "        overall_acc = report[\"accuracy\"]\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        accuracy_scores.append(overall_acc)\n",
    "\n",
    "        if best_acc < overall_acc:\n",
    "            best_acc = overall_acc\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "        if epoch - best_epoch > 10 and early_stop:\n",
    "            break\n",
    "\n",
    "    return best_model, train_losses, val_losses, accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "472ff0aa-cc35-41f4-8584-a94042d12026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T18:44:48.865825Z",
     "iopub.status.busy": "2022-07-14T18:44:48.864766Z",
     "iopub.status.idle": "2022-07-14T18:44:48.874246Z",
     "shell.execute_reply": "2022-07-14T18:44:48.872857Z",
     "shell.execute_reply.started": "2022-07-14T18:44:48.865755Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.train()\n",
    "\n",
    "    tqdm_bar = tqdm(train_loader, desc=\"Training: \")\n",
    "    for batch in tqdm_bar:\n",
    "\n",
    "        images = batch[\"img\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        batch_size = images.size(0)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        #loss = criterion(logits, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        loss_tracker.update(loss.item(), batch_size)\n",
    "\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        #batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "        #acc_tracker.update(batch_acc, batch_size)\n",
    "        tqdm_bar.set_postfix(loss=loss_tracker.avg, accuracy=acc_tracker.avg)\n",
    "        tqdm_bar.set_postfix(loss=loss_tracker.avg)\n",
    "\n",
    "    return loss_tracker.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f3903f7-15aa-4e4a-9d2d-f8a9477debdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T20:32:41.153707Z",
     "iopub.status.busy": "2022-07-14T20:32:41.153359Z",
     "iopub.status.idle": "2022-07-14T20:32:41.162490Z",
     "shell.execute_reply": "2022-07-14T20:32:41.161499Z",
     "shell.execute_reply.started": "2022-07-14T20:32:41.153681Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_bar = tqdm(val_loader, desc=\"Validation: \")\n",
    "        for batch in tqdm_bar:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            logits = model(images)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss_tracker.update(loss.item(), batch_size)\n",
    "\n",
    "            _, predicted = torch.max(probs.data, 1)\n",
    "           # batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "            #acc_tracker.update(batch_acc, batch_size)\n",
    "            acc_tracker.update(batch_size)\n",
    "\n",
    "            y_pred += predicted.tolist()\n",
    "            y_true += labels.tolist()\n",
    "            tqdm_bar.set_postfix(loss=loss_tracker.avg, accuracy=acc_tracker.avg)\n",
    "            \n",
    "\n",
    "    report = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    conf_mat = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "        \n",
    "    return loss_tracker.avg, report, conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4e9570c1-5452-4638-bead-b77061f6d648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T20:32:54.381647Z",
     "iopub.status.busy": "2022-07-14T20:32:54.380620Z",
     "iopub.status.idle": "2022-07-14T20:32:54.386609Z",
     "shell.execute_reply": "2022-07-14T20:32:54.385394Z",
     "shell.execute_reply.started": "2022-07-14T20:32:54.381600Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e17a9ee0-48c6-43df-9f7c-391be9c4325c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T20:33:26.316085Z",
     "iopub.status.busy": "2022-07-14T20:33:26.315701Z",
     "iopub.status.idle": "2022-07-14T20:34:20.905272Z",
     "shell.execute_reply": "2022-07-14T20:34:20.900941Z",
     "shell.execute_reply.started": "2022-07-14T20:33:26.316040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2049268e2a224a01ad975613951bcdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8717a22a91d147e1b0c89473a0aca684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model, train_losses, val_losses, accuracy_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m eval_accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy_scores)\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, epochs, device, early_stop)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     13\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[0;32m---> 14\u001b[0m val_loss, report, _ \u001b[38;5;241m=\u001b[39m \u001b[43mval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m overall_acc \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Input \u001b[0;32mIn [123]\u001b[0m, in \u001b[0;36mval_epoch\u001b[0;34m(model, val_loader, criterion, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m         y_true \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     30\u001b[0m         tqdm_bar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss_tracker\u001b[38;5;241m.\u001b[39mavg, accuracy\u001b[38;5;241m=\u001b[39macc_tracker\u001b[38;5;241m.\u001b[39mavg)\n\u001b[0;32m---> 33\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m conf_mat \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_tracker\u001b[38;5;241m.\u001b[39mavg, report, conf_mat\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2125\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[1;32m   2011\u001b[0m     y_true,\n\u001b[1;32m   2012\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2020\u001b[0m ):\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \n\u001b[1;32m   2023\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2125\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2128\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m/opt/conda/envs/ip4rs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "best_model, train_losses, val_losses, accuracy_scores = train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    epochs=3,\n",
    "    device=cuda_device,\n",
    ")\n",
    "eval_accuracies.append(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6fae4c3b-fa64-4335-a8a6-ee99f5c688ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T20:34:49.246737Z",
     "iopub.status.busy": "2022-07-14T20:34:49.246396Z",
     "iopub.status.idle": "2022-07-14T20:34:49.255542Z",
     "shell.execute_reply": "2022-07-14T20:34:49.254276Z",
     "shell.execute_reply.started": "2022-07-14T20:34:49.246711Z"
    }
   },
   "outputs": [],
   "source": [
    "#Testing val_epoch to test results\n",
    "#Check the following link: https://discuss.pytorch.org/t/how-to-extract-probabilities/2720/9\n",
    "\n",
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    loss_tracker = MetricTracker()\n",
    "    acc_tracker = MetricTracker()\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_bar = tqdm(val_loader, desc=\"Validation: \")\n",
    "        for batch in tqdm_bar:\n",
    "\n",
    "            images = batch[\"img\"].to(device) #Array of images\n",
    "            labels = batch[\"label\"].to(device) #Array of labels\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            logits = model(images)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            loss_tracker.update(loss.item(), batch_size)\n",
    "            predicted_prob, predicted_labels = torch.topk(probs.data, 17)\n",
    "            #predicted_prob, predicted_labels = torch.max(probs.data, 1)\n",
    "            \n",
    "            \n",
    "           # batch_acc = (predicted == labels).sum().item() / batch_size\n",
    "            #acc_tracker.update(batch_acc, batch_size)\n",
    "            acc_tracker.update(batch_size)\n",
    "\n",
    "            y_pred += predicted_labels.tolist()\n",
    "            y_true += labels.tolist()\n",
    "            \n",
    "            y_pred_arr = np.array(y_pred)\n",
    "            y_true_arr = np.array(y_true)\n",
    "            \n",
    "        \n",
    "        return images, labels, y_pred_arr, y_true_arr, logits, probs, predicted_labels\n",
    "          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "60658d9b-5726-489a-ae80-d9beb439b73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T20:39:33.484832Z",
     "iopub.status.busy": "2022-07-14T20:39:33.484458Z",
     "iopub.status.idle": "2022-07-14T20:39:34.620463Z",
     "shell.execute_reply": "2022-07-14T20:39:34.619420Z",
     "shell.execute_reply.started": "2022-07-14T20:39:33.484805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7377bcec184a88aaad7cac6fab25bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y true values are:  [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "(210, 17)\n",
      "Y prediction values are:  [[10  9  3 ... 11  4 14]\n",
      " [ 8 10  1 ...  9 16 12]\n",
      " [10  3  8 ...  0  4  9]\n",
      " ...\n",
      " [10 11  3 ...  6 13  5]\n",
      " [ 3 10 15 ... 13  0  4]\n",
      " [10  8  1 ...  7 13  6]]\n",
      "(210, 17)\n"
     ]
    }
   ],
   "source": [
    "#Idea taken from the following website: https://colab.research.google.com/github/kmkarakaya/ML_tutorials/blob/master/Multi_Label_Model_Evaulation.ipynb#scrollTo=H8WBPN1OxXmw\n",
    "# We have 210 values because our validation takes 10% of our data so we get 210 values out of 2100\n",
    "im, lb, y_prediction, y_true, log, probs, pre = val_epoch(model, val_loader, criterion, cuda_device)\n",
    "print(\"Y true values are: \", y_true)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(\"Y prediction values are: \", y_prediction)\n",
    "print(y_prediction.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9098f6-fc54-42d6-80f0-2b6ff87f65bb",
   "metadata": {},
   "source": [
    "## Test Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cb19afdb-14a7-447f-b8e4-23cd154cf5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T20:39:36.248375Z",
     "iopub.status.busy": "2022-07-14T20:39:36.247382Z",
     "iopub.status.idle": "2022-07-14T20:39:36.265008Z",
     "shell.execute_reply": "2022-07-14T20:39:36.263543Z",
     "shell.execute_reply.started": "2022-07-14T20:39:36.248345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images tensor([[[[-0.3826, -0.3217, -0.3420,  ..., -0.8905, -1.2562, -1.3984],\n",
      "          [-0.2201, -0.2201, -0.1795,  ..., -2.1298, -2.3939, -2.4548],\n",
      "          [-0.1388, -0.1591, -0.0779,  ..., -2.1298, -1.6828, -1.1952],\n",
      "          ...,\n",
      "          [-0.5248, -0.4639, -0.5451,  ..., -0.0372,  0.0643, -0.0372],\n",
      "          [-0.5655, -0.5858, -0.6264,  ...,  0.0440, -0.1795, -0.1795],\n",
      "          [-0.7077, -0.6467, -0.6061,  ..., -0.2607,  0.0237,  0.2472]],\n",
      "\n",
      "         [[ 1.1388,  1.1702,  1.0446,  ...,  0.9504,  0.4482,  0.1342],\n",
      "          [ 1.3271,  1.3271,  1.3271,  ..., -1.0900, -1.5609, -1.7492],\n",
      "          [ 1.3585,  1.3585,  1.4213,  ..., -1.6865, -1.2470, -0.7447],\n",
      "          ...,\n",
      "          [ 1.3271,  1.4213,  1.4527,  ...,  2.2061,  2.4258,  2.2375],\n",
      "          [ 1.4527,  1.4213,  1.3899,  ...,  2.3002,  1.9549,  1.9549],\n",
      "          [ 1.3585,  1.3271,  1.3585,  ...,  1.8294,  2.2061,  2.5200]],\n",
      "\n",
      "         [[ 1.6220,  1.6591,  1.5849,  ...,  1.5849,  1.0288,  0.7322],\n",
      "          [ 1.8445,  1.8445,  1.8815,  ..., -0.2688, -0.6767, -0.8620],\n",
      "          [ 1.9928,  1.8445,  1.8815,  ..., -0.6767, -0.1947,  0.4727],\n",
      "          ...,\n",
      "          [ 1.8815,  1.9557,  1.8815,  ...,  3.3645,  3.5870,  3.4016],\n",
      "          [ 1.8445,  1.8074,  1.7703,  ...,  3.5128,  3.1050,  2.9938],\n",
      "          [ 1.5849,  1.6220,  1.7703,  ...,  2.9196,  3.2904,  3.4758]]],\n",
      "\n",
      "\n",
      "        [[[-1.8453, -1.7438, -0.6670,  ..., -1.1546, -0.8499, -1.2968],\n",
      "          [-1.7641, -1.5406, -1.6828,  ..., -1.3171, -1.0937, -1.1749],\n",
      "          [-1.6016, -1.4187, -1.5812,  ..., -1.3984, -1.1343, -0.9718],\n",
      "          ...,\n",
      "          [-2.0485, -2.2517, -1.9876,  ..., -0.0779, -1.0530, -1.1749],\n",
      "          [-1.9672, -2.2517, -1.8860,  ..., -0.1998, -1.0530, -1.1546],\n",
      "          [-2.1907, -2.2313, -1.7031,  ..., -0.1998, -1.0937, -1.4187]],\n",
      "\n",
      "         [[ 0.1342,  0.2284,  1.3585,  ...,  0.8562,  1.3899,  0.7935],\n",
      "          [ 0.2912,  0.5737,  0.2284,  ...,  0.6679,  1.0760,  0.9818],\n",
      "          [ 0.6051,  0.8248,  0.4482,  ...,  0.5737,  1.0132,  1.2957],\n",
      "          ...,\n",
      "          [-0.4308, -0.6505, -0.1169,  ...,  2.0491,  1.1074,  1.0132],\n",
      "          [-0.2425, -0.5878,  0.1656,  ...,  1.9863,  1.1074,  0.8876],\n",
      "          [-0.5250, -0.4936,  0.5737,  ...,  2.0491,  1.0446,  0.5423]],\n",
      "\n",
      "         [[-0.4913, -0.4542,  0.9547,  ...,  0.3615,  0.6581,  0.2873],\n",
      "          [-0.3430, -0.1947, -0.3059,  ...,  0.1019,  0.3244,  0.3244],\n",
      "          [-0.1947, -0.0093, -0.2688,  ...,  0.1019,  0.3985,  0.5839],\n",
      "          ...,\n",
      "          [-0.7508, -1.0474, -0.6396,  ...,  1.7332,  0.5839,  0.3615],\n",
      "          [-0.6025, -0.8991, -0.2688,  ...,  1.6962,  0.5839,  0.3985],\n",
      "          [-0.8991, -0.7879,  0.0278,  ...,  1.8815,  0.6581,  0.1019]]],\n",
      "\n",
      "\n",
      "        [[[-0.3014, -0.3014, -0.3217,  ...,  0.5519,  0.5519,  0.9176],\n",
      "          [-0.3217, -0.3217, -0.3217,  ...,  0.5925,  0.8770,  0.9989],\n",
      "          [-0.3014, -0.3420, -0.3420,  ...,  0.9176,  1.0192,  0.9785],\n",
      "          ...,\n",
      "          [ 0.4300,  0.3691,  0.3284,  ...,  0.0846,  0.2472,  0.3284],\n",
      "          [ 0.4503,  0.5316,  0.7957,  ...,  0.1456,  0.1862,  0.2878],\n",
      "          [ 0.5113,  0.8770,  0.9582,  ...,  0.3081,  0.1253,  0.2065]],\n",
      "\n",
      "         [[ 0.8562,  0.8876,  0.8562,  ...,  2.3944,  2.3630,  2.7711],\n",
      "          [ 0.8876,  0.8876,  0.8562,  ...,  2.4258,  2.7083,  2.8653],\n",
      "          [ 0.8876,  0.8562,  0.8562,  ...,  2.7711,  2.8653,  2.8339],\n",
      "          ...,\n",
      "          [ 2.1747,  2.0805,  1.9863,  ...,  1.6096,  1.9549,  2.0805],\n",
      "          [ 2.1433,  2.2375,  2.5828,  ...,  1.6724,  1.8608,  2.0177],\n",
      "          [ 2.2061,  2.6455,  2.7397,  ...,  1.9863,  1.7352,  1.8922]],\n",
      "\n",
      "         [[ 0.7322,  0.7693,  0.6951,  ...,  2.4747,  2.4006,  2.7343],\n",
      "          [ 0.7322,  0.7322,  0.6951,  ...,  2.4377,  2.6972,  2.8084],\n",
      "          [ 0.6951,  0.6210,  0.6951,  ...,  2.7713,  2.8826,  2.7713],\n",
      "          ...,\n",
      "          [ 2.1781,  2.0669,  1.9557,  ...,  1.3996,  1.9186,  2.0669],\n",
      "          [ 2.1040,  2.2152,  2.5118,  ...,  1.4737,  1.7332,  2.0298],\n",
      "          [ 2.1411,  2.6230,  2.7343,  ...,  1.9186,  1.5479,  1.9186]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3081,  0.2472,  0.3284,  ..., -0.8702, -0.8702, -0.6670],\n",
      "          [ 0.2472,  0.1862,  0.1050,  ..., -0.9311, -0.6670, -0.0169],\n",
      "          [ 0.1659, -0.0169,  0.1253,  ..., -0.6873, -0.0779, -0.4842],\n",
      "          ...,\n",
      "          [-0.7686, -0.7686, -0.7889,  ..., -1.0530, -1.0530, -1.0530],\n",
      "          [-0.7686, -0.7889, -0.7686,  ..., -1.0327, -1.0124, -0.9921],\n",
      "          [-0.8092, -0.7483, -0.6873,  ..., -1.0124, -1.0124, -0.9515]],\n",
      "\n",
      "         [[ 1.7352,  1.6724,  1.7666,  ...,  0.1656,  0.1342,  0.4795],\n",
      "          [ 1.6410,  1.5468,  1.4213,  ...,  0.0715,  0.4795,  1.5468],\n",
      "          [ 1.4841,  1.2015,  1.4527,  ...,  0.4482,  1.4527,  0.7935],\n",
      "          ...,\n",
      "          [ 0.3226,  0.3226,  0.2598,  ..., -0.1483, -0.1483, -0.0855],\n",
      "          [ 0.3226,  0.2598,  0.3226,  ..., -0.1169, -0.0541, -0.0541],\n",
      "          [ 0.2912,  0.3540,  0.4795,  ..., -0.1169, -0.0855, -0.0227]],\n",
      "\n",
      "         [[ 1.5849,  1.5108,  1.6220,  ...,  0.1390,  0.0649,  0.4356],\n",
      "          [ 1.4366,  1.2883,  1.1030,  ..., -0.0093,  0.4727,  1.6220],\n",
      "          [ 1.2142,  0.8064,  1.0659,  ...,  0.3985,  1.5479,  0.7693],\n",
      "          ...,\n",
      "          [ 0.3244,  0.3244,  0.2873,  ..., -0.4913, -0.4913, -0.3800],\n",
      "          [ 0.3615,  0.2873,  0.3615,  ..., -0.3430, -0.2688, -0.3059],\n",
      "          [ 0.2502,  0.3985,  0.6210,  ..., -0.3430, -0.3800, -0.2688]]],\n",
      "\n",
      "\n",
      "        [[[-1.1546, -0.6670, -0.3420,  ..., -1.3171, -1.6828, -1.6016],\n",
      "          [-1.3781, -1.0733, -0.5858,  ..., -0.2810, -0.3217, -0.3217],\n",
      "          [-1.2968, -1.1749, -0.6061,  ..., -0.2404, -0.2201, -0.2201],\n",
      "          ...,\n",
      "          [-0.1591, -0.8905, -1.2968,  ..., -1.1546, -0.8702, -1.1749],\n",
      "          [-0.1998, -0.6467, -0.9718,  ..., -0.9311, -0.5045, -1.0327],\n",
      "          [-0.1591, -0.6467, -0.8499,  ..., -0.9718, -0.2607, -0.7483]],\n",
      "\n",
      "         [[-0.0227,  0.7307,  1.1702,  ...,  0.3854, -0.1483, -0.1797],\n",
      "          [-0.3366,  0.1028,  0.8562,  ...,  1.7352,  1.7666,  1.7980],\n",
      "          [-0.2111,  0.1028,  0.9190,  ...,  1.6724,  1.7038,  1.7352],\n",
      "          ...,\n",
      "          [ 1.9235,  0.8248,  0.0715,  ...,  0.1028,  0.6051,  0.0715],\n",
      "          [ 1.9235,  1.2643,  0.6679,  ...,  0.5109,  1.1388,  0.3226],\n",
      "          [ 1.9549,  1.2329,  0.8562,  ...,  0.5109,  1.5782,  0.7935]],\n",
      "\n",
      "         [[ 0.4727,  0.9917,  1.4366,  ...,  1.1771,  0.5098,  0.3985],\n",
      "          [ 0.3244,  0.5839,  1.2142,  ...,  2.6230,  2.5860,  2.6601],\n",
      "          [ 0.5098,  0.5098,  1.3625,  ...,  2.6230,  2.6972,  2.7343],\n",
      "          ...,\n",
      "          [ 1.8815,  1.0288,  0.4356,  ...,  0.2873,  0.9547,  0.5839],\n",
      "          [ 1.8074,  1.3254,  0.8805,  ...,  0.8805,  1.5108,  0.7693],\n",
      "          [ 1.9186,  1.2883,  1.0659,  ...,  0.7693,  1.7703,  1.0659]]],\n",
      "\n",
      "\n",
      "        [[[-0.5655, -0.6061, -0.6467,  ...,  0.4706,  0.3894,  0.5722],\n",
      "          [-0.5655, -0.6061, -0.5451,  ...,  0.6941,  0.8770,  0.7348],\n",
      "          [-1.0124, -0.8296, -0.4639,  ..., -0.0169,  0.9176,  0.9379],\n",
      "          ...,\n",
      "          [-0.7889, -0.8296, -1.0733,  ..., -0.9718, -0.6264, -0.7280],\n",
      "          [-0.8296, -0.9921, -1.1749,  ..., -1.1140, -1.0530, -0.9718],\n",
      "          [-0.8092, -1.0733, -1.1546,  ..., -1.0733, -1.0530, -0.8092]],\n",
      "\n",
      "         [[ 0.9504,  0.9190,  0.8562,  ...,  2.4258,  2.2688,  2.5200],\n",
      "          [ 0.9818,  0.8876,  0.9818,  ...,  2.8339,  3.0536,  2.8025],\n",
      "          [ 0.3540,  0.6365,  1.1388,  ...,  1.7666,  3.0850,  3.0536],\n",
      "          ...,\n",
      "          [ 0.5423,  0.6365,  0.3540,  ...,  0.6679,  1.0760,  0.8562],\n",
      "          [ 0.6679,  0.5109,  0.1656,  ...,  0.5423,  0.5109,  0.5737],\n",
      "          [ 0.8562,  0.4168,  0.0401,  ...,  0.5737,  0.5423,  0.7621]],\n",
      "\n",
      "         [[ 0.7693,  0.7322,  0.7322,  ...,  2.6972,  2.5860,  2.9196],\n",
      "          [ 0.8805,  0.8434,  0.9547,  ...,  3.1050,  3.5128,  3.2162],\n",
      "          [ 0.0278,  0.3615,  1.0288,  ...,  1.8074,  3.5870,  3.5499],\n",
      "          ...,\n",
      "          [ 0.2873,  0.3244, -0.0093,  ...,  0.3985,  0.9917,  0.6210],\n",
      "          [ 0.3244,  0.1019, -0.2688,  ...,  0.1390,  0.2873,  0.2873],\n",
      "          [ 0.4356,  0.0278, -0.3059,  ...,  0.1761,  0.1390,  0.5098]]]])\n",
      "Images shape torch.Size([18, 3, 64, 64])\n",
      "Label tensor([[0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "Label shape torch.Size([18, 17])\n"
     ]
    }
   ],
   "source": [
    "print(\"Images\", im)\n",
    "print(\"Images shape\", im.shape)\n",
    "\n",
    "print(\"Label\", lb)\n",
    "print(\"Label shape\", lb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "25a0ad7a-f470-4a4a-9de2-72f231c5a941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T20:14:38.915758Z",
     "iopub.status.busy": "2022-07-14T20:14:38.915393Z",
     "iopub.status.idle": "2022-07-14T20:14:38.932935Z",
     "shell.execute_reply": "2022-07-14T20:14:38.931839Z",
     "shell.execute_reply.started": "2022-07-14T20:14:38.915715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[ -5.1581,   0.3914,   1.7470,  -1.5012,  -6.2783,  -5.2867,  -7.0403,\n",
      "          -6.6120,  -1.2838,  -6.2936,   3.0286,  -2.0860,  -5.5985,  -6.6849,\n",
      "           3.9404,  -1.2268,  -8.9678],\n",
      "        [ -7.0603,  -2.4734,   1.5256,  -2.7421,  -6.1616,  -1.2679,  -5.9548,\n",
      "          -6.2588,   4.5558,  -6.1958,   2.0909,  -3.4977,  -6.5851,  -5.2587,\n",
      "          -5.4385,   3.2597,  -4.7059],\n",
      "        [  3.8615,  -3.4650,   1.2770,  -0.7040,  -5.6518,  -7.1856,  -6.1340,\n",
      "          -7.5348,  -1.6172,  -5.9145,   5.6845,  -3.7778,  -6.2146,  -5.4458,\n",
      "          -1.9188,  -5.9091,  -7.4834],\n",
      "        [ -2.6568,  -2.6369,  -4.5690,  -2.2128,  -3.7092,  -6.8848,  -4.9252,\n",
      "          -5.0502,  -1.2266,  -6.6037,  -0.8466,   1.4938,   1.6582,  -3.8813,\n",
      "          -2.9261,  -3.7825,  -3.1287],\n",
      "        [ -6.0245,  -1.0564,   2.3203,   1.2047,  -6.4674,  -2.1483,  -7.1153,\n",
      "          -6.0587,   2.4351,  -5.8091,   2.9217,  -7.1310,  -6.7172,  -6.4234,\n",
      "          -2.8768,   0.7744,  -8.9534],\n",
      "        [-15.6810,   5.4570,   1.2526, -11.6004, -13.1292,  -1.5539, -12.9247,\n",
      "         -12.1730,  10.5759, -13.8664,   2.3476,  -7.9005, -11.7618, -10.3738,\n",
      "          -2.6573,  -4.3899, -12.4977],\n",
      "        [-11.3883,  -6.7281,  -8.8588,  -6.8017,  -9.3086, -10.3432, -11.1829,\n",
      "          -8.8880,  -6.6898,  -8.4113,  -5.9080,  -6.4948,  -9.8135,  -9.9024,\n",
      "         -10.0130,   6.7357,  -4.8810],\n",
      "        [ -2.7778,  -2.6037,  -7.0006,  -2.8722,  -8.4017,  -7.2767,  -9.2886,\n",
      "          -8.9932,   5.7551,  -9.5221,   7.6306,  -5.4548,  -8.6829,  -8.0881,\n",
      "          -6.2027,  -6.8041, -11.0485],\n",
      "        [  0.9536,  -5.4712,  -3.9943,  -2.0701,  -5.3327, -10.8644,  -8.0385,\n",
      "          -7.6594,  -2.9610,  -8.5893,   2.0678,   0.8252,   0.0298,  -6.3467,\n",
      "          -1.6845,  -8.0413,  -7.7025],\n",
      "        [ -5.3960,   1.0442,   2.3220,   0.9220,  -4.8558,  -3.8026,  -5.3590,\n",
      "          -5.8933,  -0.9664,  -4.1942,   2.1046,  -4.6179,  -5.5461,  -5.4516,\n",
      "          -2.7932,   1.2545,  -6.0754],\n",
      "        [ -5.9114,   0.0220,   1.1806,   1.6716,  -4.5194,  -4.3662,  -5.1661,\n",
      "          -5.2117,  -0.9819,  -0.4460,   3.2517,  -6.1693,  -5.6733,  -4.4788,\n",
      "          -4.5712,   1.6436,  -4.9221],\n",
      "        [ -5.7882,  -1.1624,  -2.8617,  -4.3638,  -6.4607,  -4.7797,  -3.6737,\n",
      "          -5.6212,   3.0317,  -6.1942,  -1.0555,  -0.3423,  -3.5896,  -3.7819,\n",
      "          -5.1490,  -0.4184,   1.4061],\n",
      "        [ -4.6573,  -1.7012,   2.0564,  -1.2167,  -5.0834,  -4.8408,  -6.5772,\n",
      "          -5.8285,  -1.8867,  -4.9983,   1.0315,  -2.6314,  -5.7178,  -6.1882,\n",
      "           1.9382,   0.7356,  -7.1576],\n",
      "        [ -1.2379,  -1.5004,   0.5825,   1.3892,  -4.3575,  -3.7889,  -4.9635,\n",
      "          -5.3046,  -1.5718,  -4.4734,   3.3424,  -4.8551,  -4.9722,  -4.3568,\n",
      "          -1.8380,  -1.5924,  -6.0804],\n",
      "        [ -5.1422,  -0.3441,   2.5319,   0.7834,  -5.9878,  -3.1838,  -5.5644,\n",
      "          -5.7243,   0.6453,  -4.6194,   2.8245,  -4.5051,  -5.6336,  -5.9094,\n",
      "          -2.8016,   1.5004,  -6.2280],\n",
      "        [ -2.9478,  -5.6546,  -8.1837,  -5.9910,  -7.2549, -11.5145,  -7.8426,\n",
      "          -6.7570,  -1.0866,  -9.8672,   3.0571,   1.7760,  -1.3307,  -7.2471,\n",
      "          -6.8263,  -7.9672,  -9.5244],\n",
      "        [ -7.0477,  -2.6988,   1.8844,   0.7254,  -6.6443,  -4.1569,  -7.2083,\n",
      "          -6.4826,   0.2202,  -3.6653,   1.4168,  -6.3632,  -6.1857,  -6.5386,\n",
      "          -5.5794,   3.3347,  -6.3861],\n",
      "        [ -3.9712,   0.0868,   0.5909,  -2.6453,  -5.4059,  -5.2552,  -5.6209,\n",
      "          -5.5991,   0.1122,  -5.6410,   2.2442,   0.5338,  -4.8492,  -5.1109,\n",
      "           1.5758,  -1.9072,  -6.5199]])\n",
      "Logits shape: torch.Size([18, 17])\n",
      "Probs: tensor([[7.1671e-05, 1.8427e-02, 7.1480e-02, 2.7765e-03, 2.3381e-05, 6.3022e-05,\n",
      "         1.0912e-05, 1.6747e-05, 3.4511e-03, 2.3026e-05, 2.5750e-01, 1.5473e-03,\n",
      "         4.6140e-05, 1.5570e-05, 6.4089e-01, 3.6532e-03, 1.5878e-06],\n",
      "        [6.3877e-06, 6.2718e-04, 3.4211e-02, 4.7944e-04, 1.5690e-05, 2.0939e-03,\n",
      "         1.9296e-05, 1.4238e-05, 7.0818e-01, 1.5163e-05, 6.0210e-02, 2.2521e-04,\n",
      "         1.0274e-05, 3.8706e-05, 3.2337e-05, 1.9375e-01, 6.7273e-05],\n",
      "        [1.3726e-01, 9.0303e-05, 1.0355e-02, 1.4282e-03, 1.0139e-05, 2.1872e-06,\n",
      "         6.2601e-06, 1.5425e-06, 5.7303e-04, 7.7963e-06, 8.4975e-01, 6.6046e-05,\n",
      "         5.7755e-06, 1.2459e-05, 4.2386e-04, 7.8391e-06, 1.6238e-06],\n",
      "        [6.4567e-03, 6.5862e-03, 9.5394e-04, 1.0065e-02, 2.2540e-03, 9.4147e-05,\n",
      "         6.6808e-04, 5.8963e-04, 2.6985e-02, 1.2471e-04, 3.9459e-02, 4.0979e-01,\n",
      "         4.8302e-01, 1.8975e-03, 4.9323e-03, 2.0946e-03, 4.0278e-03],\n",
      "        [5.2343e-05, 7.5245e-03, 2.2027e-01, 7.2191e-02, 3.3615e-05, 2.5250e-03,\n",
      "         1.7585e-05, 5.0583e-05, 2.4708e-01, 6.4926e-05, 4.0194e-01, 1.7310e-05,\n",
      "         2.6184e-05, 3.5127e-05, 1.2187e-03, 4.6946e-02, 2.7982e-06],\n",
      "        [3.9268e-12, 5.9449e-03, 8.8758e-05, 2.3240e-10, 5.0383e-11, 5.3625e-06,\n",
      "         6.1817e-11, 1.3108e-10, 9.9369e-01, 2.4107e-11, 2.6532e-04, 9.3988e-09,\n",
      "         1.9775e-10, 7.9240e-10, 1.7789e-06, 3.1458e-07, 9.4742e-11],\n",
      "        [1.3453e-08, 1.4215e-06, 1.6881e-07, 1.3205e-06, 1.0765e-07, 3.8256e-08,\n",
      "         1.6520e-08, 1.6394e-07, 1.4769e-06, 2.6406e-07, 3.2276e-06, 1.7949e-06,\n",
      "         6.4977e-08, 5.9451e-08, 5.3224e-08, 9.9998e-01, 9.0135e-06],\n",
      "        [2.6165e-05, 3.1141e-05, 3.8351e-07, 2.3808e-05, 9.4474e-08, 2.9098e-07,\n",
      "         3.8917e-08, 5.2292e-08, 1.3289e-01, 3.0811e-08, 8.6702e-01, 1.7994e-06,\n",
      "         7.1316e-08, 1.2926e-07, 8.5178e-07, 4.6679e-07, 6.6959e-09],\n",
      "        [1.8263e-01, 2.9602e-04, 1.2964e-03, 8.8799e-03, 3.3997e-04, 1.3460e-06,\n",
      "         2.2717e-05, 3.3188e-05, 3.6432e-03, 1.3096e-05, 5.5649e-01, 1.6062e-01,\n",
      "         7.2505e-02, 1.2333e-04, 1.3057e-02, 2.2653e-05, 3.1787e-05],\n",
      "        [1.6324e-04, 1.0227e-01, 3.6702e-01, 9.0505e-02, 2.8017e-04, 8.0319e-04,\n",
      "         1.6938e-04, 9.9276e-05, 1.3695e-02, 5.4295e-04, 2.9531e-01, 3.5543e-04,\n",
      "         1.4048e-04, 1.5440e-04, 2.2040e-03, 1.2621e-01, 8.2745e-05],\n",
      "        [6.4956e-05, 2.4518e-02, 7.8098e-02, 1.2762e-01, 2.6132e-04, 3.0457e-04,\n",
      "         1.3687e-04, 1.3077e-04, 8.9841e-03, 1.5354e-02, 6.1961e-01, 5.0194e-05,\n",
      "         8.2420e-05, 2.7215e-04, 2.4812e-04, 1.2409e-01, 1.7470e-04],\n",
      "        [1.1342e-04, 1.1578e-02, 2.1166e-03, 4.7130e-04, 5.7892e-05, 3.1094e-04,\n",
      "         9.3971e-04, 1.3403e-04, 7.6753e-01, 7.5569e-05, 1.2885e-02, 2.6291e-02,\n",
      "         1.0222e-03, 8.4331e-04, 2.1493e-04, 2.4366e-02, 1.5105e-01],\n",
      "        [4.6535e-04, 8.9453e-03, 3.8323e-01, 1.4521e-02, 3.0387e-04, 3.8731e-04,\n",
      "         6.8226e-05, 1.4424e-04, 7.4301e-03, 3.3088e-04, 1.3752e-01, 3.5287e-03,\n",
      "         1.6114e-04, 1.0067e-04, 3.4052e-01, 1.0230e-01, 3.8183e-05],\n",
      "        [8.2242e-03, 6.3253e-03, 5.0778e-02, 1.1378e-01, 3.6329e-04, 6.4151e-04,\n",
      "         1.9819e-04, 1.4092e-04, 5.8897e-03, 3.2356e-04, 8.0221e-01, 2.2088e-04,\n",
      "         1.9648e-04, 3.6357e-04, 4.5130e-03, 5.7698e-03, 6.4866e-05],\n",
      "        [1.5039e-04, 1.8238e-02, 3.2362e-01, 5.6321e-02, 6.4560e-05, 1.0659e-03,\n",
      "         9.8593e-05, 8.4027e-05, 4.9053e-02, 2.5366e-04, 4.3363e-01, 2.8439e-04,\n",
      "         9.1997e-05, 6.9825e-05, 1.5622e-03, 1.1536e-01, 5.0775e-05],\n",
      "        [1.8844e-03, 1.2577e-04, 1.0029e-05, 8.9848e-05, 2.5387e-05, 3.5868e-07,\n",
      "         1.4106e-05, 4.1768e-05, 1.2119e-02, 1.8626e-06, 7.6394e-01, 2.1218e-01,\n",
      "         9.4939e-03, 2.5585e-05, 3.8972e-05, 1.2453e-05, 2.6242e-06],\n",
      "        [2.0596e-05, 1.5941e-03, 1.5594e-01, 4.8932e-02, 3.0831e-05, 3.7090e-04,\n",
      "         1.7540e-05, 3.6241e-05, 2.9526e-02, 6.0641e-04, 9.7694e-02, 4.0838e-05,\n",
      "         4.8768e-05, 3.4267e-05, 8.9427e-05, 6.6498e-01, 3.9915e-05],\n",
      "        [9.3035e-04, 5.3826e-02, 8.9109e-02, 3.5033e-03, 2.2159e-04, 2.5763e-04,\n",
      "         1.7873e-04, 1.8267e-04, 5.5215e-02, 1.7516e-04, 4.6556e-01, 8.4167e-02,\n",
      "         3.8668e-04, 2.9762e-04, 2.3859e-01, 7.3290e-03, 7.2739e-05]])\n",
      "Probs Shape: torch.Size([18, 17])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits:\", log)\n",
    "print(\"Logits shape:\", log.shape)\n",
    "\n",
    "print(\"Probs:\", probs)\n",
    "print(\"Probs Shape:\", probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f88d8e9c-480f-40e5-8f29-6a41c31c5c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T19:23:08.715710Z",
     "iopub.status.busy": "2022-07-14T19:23:08.715362Z",
     "iopub.status.idle": "2022-07-14T19:23:08.721463Z",
     "shell.execute_reply": "2022-07-14T19:23:08.720328Z",
     "shell.execute_reply.started": "2022-07-14T19:23:08.715683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([14,  8, 10, 12, 10,  8, 15, 10, 10,  2, 10,  8,  2, 10, 10, 10, 15, 10])\n",
      "Prediction shape: torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction:\", pre)\n",
    "print(\"Prediction shape:\", pre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17d945-9ed1-4b6a-92b2-3b42aa1d3653",
   "metadata": {},
   "source": [
    "# Test Bravo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d6b67-ab1f-4b50-b9ad-feeb784b23e6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-14T18:45:40.086440Z",
     "iopub.status.idle": "2022-07-14T18:45:40.086961Z",
     "shell.execute_reply": "2022-07-14T18:45:40.086711Z",
     "shell.execute_reply.started": "2022-07-14T18:45:40.086684Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can normalize the y_prediction values between 0 & 1\n",
    "y_prediction_normalize = []\n",
    "min_val = min(y_prediction)\n",
    "max_val = max(y_prediction)\n",
    "for i in range(len(y_prediction)):\n",
    "    z = ((y_prediction[i] - min_val)/ (max_val -min_val))\n",
    "    y_prediction_normalize.append(z)\n",
    "    \n",
    "y_prediction_normalize\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7104c54-3ad8-4be8-9313-6df69ab9604f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-14T18:45:40.090821Z",
     "iopub.status.idle": "2022-07-14T18:45:40.091136Z",
     "shell.execute_reply": "2022-07-14T18:45:40.090988Z",
     "shell.execute_reply.started": "2022-07-14T18:45:40.090972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Threshold: Let's assume we are using 0.5 as the threshold for prediction\n",
    "\n",
    "y_pred_final=[]\n",
    "for sample in  y_prediction_normalize:\n",
    "    if sample > 0.5:\n",
    "        y_pred_final.append(1)\n",
    "    else:\n",
    "        y_pred_final.append(0)\n",
    "        \n",
    "y_pred_final = np.array(y_pred_final)\n",
    "y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616fb95c-9f4e-454e-a684-1baa44cccd15",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-14T18:45:40.094435Z",
     "iopub.status.idle": "2022-07-14T18:45:40.094748Z",
     "shell.execute_reply": "2022-07-14T18:45:40.094601Z",
     "shell.execute_reply.started": "2022-07-14T18:45:40.094586Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_true, y_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4024a-4d28-4e02-8b02-0429c9f4291b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-14T18:45:40.098646Z",
     "iopub.status.idle": "2022-07-14T18:45:40.098956Z",
     "shell.execute_reply": "2022-07-14T18:45:40.098809Z",
     "shell.execute_reply.started": "2022-07-14T18:45:40.098793Z"
    }
   },
   "outputs": [],
   "source": [
    "def prettify_confusion_matrix(conf_mat, class_names):\n",
    "    plt.subplots(1, 1, figsize=(11, 7))\n",
    "    sns.heatmap(\n",
    "        conf_mat,\n",
    "        cmap=\"viridis\",\n",
    "        fmt=\"g\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        annot=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182cfa4-5293-487e-aed3-c6b3b9eaa48d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-14T18:45:40.104031Z",
     "iopub.status.idle": "2022-07-14T18:45:40.104493Z",
     "shell.execute_reply": "2022-07-14T18:45:40.104331Z",
     "shell.execute_reply.started": "2022-07-14T18:45:40.104310Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_t = np.array([[0, 1, 1, 1],[0,0,1,0],[1,1,0,0]])\n",
    "y_p = np.array([[0, 1, 0, 1],\n",
    "       [0, 1, 1, 1],\n",
    "       [1, 0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ec2bd-e1b6-4fbb-9f14-c78c8f5bf61c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-14T18:45:40.108967Z",
     "iopub.status.idle": "2022-07-14T18:45:40.109288Z",
     "shell.execute_reply": "2022-07-14T18:45:40.109142Z",
     "shell.execute_reply.started": "2022-07-14T18:45:40.109125Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "st = multilabel_confusion_matrix(y_t, y_p)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5127e-64ca-4c6f-963f-c3baf99d9928",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-14T18:45:40.112639Z",
     "iopub.status.idle": "2022-07-14T18:45:40.113013Z",
     "shell.execute_reply": "2022-07-14T18:45:40.112863Z",
     "shell.execute_reply.started": "2022-07-14T18:45:40.112846Z"
    }
   },
   "outputs": [],
   "source": [
    "abel_names = ['label A', 'label B', 'label C', 'label D']\n",
    "\n",
    "print(classification_report(y_t, y_pr,target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdb3c2-acc9-47ac-a295-e590848da635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a2b36-f078-46b7-8ed5-246f3a8677cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e5b30-a747-4599-97f2-0a18cc13be33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b4ebd-8f48-4d3d-a193-4e4c4f296663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851df786-d2c2-4756-a1f5-c7bf830d089f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d242938-fd6b-470a-a271-b4d631c42a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f4cfb-03c9-4420-ba69-4da9ea643312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929061bd-9125-4bf0-91df-1c096a333e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa0d4d-fc41-45f1-a3cc-ea835fd2f282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b05ad8-a6b8-4f3e-a553-bc850daf5156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171a4ef-ade1-4c2b-b9af-708655bde7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb60e36-f55b-4645-82c4-bd77bdbb95e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bf598-3d58-4ec9-9779-be34b2804d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f775b0-5f6d-4442-9d27-b77c8ab89d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0489f1-9fe1-481b-a517-7f4fce4e7b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac7fb6-a7ac-4863-ad8d-fff6c9febca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0773d-1d0d-4127-bc79-526dbbb87b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff31dda-829d-46a4-afd7-dd66d353ab41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip4rs",
   "language": "python",
   "name": "ip4rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
